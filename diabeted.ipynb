{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "\r\n",
    "df = pd.read_csv(\"Diabeted_Ensemble.csv\")\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Triceps skin fold thickness</th>\n",
       "      <th>2-Hour serum insulin</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age (years)</th>\n",
       "      <th>Class variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Number of times pregnant   Plasma glucose concentration  \\\n",
       "0                            6                            148   \n",
       "1                            1                             85   \n",
       "2                            8                            183   \n",
       "3                            1                             89   \n",
       "4                            0                            137   \n",
       "..                         ...                            ...   \n",
       "763                         10                            101   \n",
       "764                          2                            122   \n",
       "765                          5                            121   \n",
       "766                          1                            126   \n",
       "767                          1                             93   \n",
       "\n",
       "      Diastolic blood pressure   Triceps skin fold thickness  \\\n",
       "0                           72                            35   \n",
       "1                           66                            29   \n",
       "2                           64                             0   \n",
       "3                           66                            23   \n",
       "4                           40                            35   \n",
       "..                         ...                           ...   \n",
       "763                         76                            48   \n",
       "764                         70                            27   \n",
       "765                         72                            23   \n",
       "766                         60                             0   \n",
       "767                         70                            31   \n",
       "\n",
       "      2-Hour serum insulin   Body mass index   Diabetes pedigree function  \\\n",
       "0                        0              33.6                        0.627   \n",
       "1                        0              26.6                        0.351   \n",
       "2                        0              23.3                        0.672   \n",
       "3                       94              28.1                        0.167   \n",
       "4                      168              43.1                        2.288   \n",
       "..                     ...               ...                          ...   \n",
       "763                    180              32.9                        0.171   \n",
       "764                      0              36.8                        0.340   \n",
       "765                    112              26.2                        0.245   \n",
       "766                      0              30.1                        0.349   \n",
       "767                      0              30.4                        0.315   \n",
       "\n",
       "      Age (years)  Class variable  \n",
       "0              50             YES  \n",
       "1              31              NO  \n",
       "2              32             YES  \n",
       "3              21              NO  \n",
       "4              33             YES  \n",
       "..            ...             ...  \n",
       "763            63              NO  \n",
       "764            27              NO  \n",
       "765            30              NO  \n",
       "766            47             YES  \n",
       "767            23              NO  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0    Number of times pregnant      768 non-null    int64  \n",
      " 1    Plasma glucose concentration  768 non-null    int64  \n",
      " 2    Diastolic blood pressure      768 non-null    int64  \n",
      " 3    Triceps skin fold thickness   768 non-null    int64  \n",
      " 4    2-Hour serum insulin          768 non-null    int64  \n",
      " 5    Body mass index               768 non-null    float64\n",
      " 6    Diabetes pedigree function    768 non-null    float64\n",
      " 7    Age (years)                   768 non-null    int64  \n",
      " 8    Class variable                768 non-null    object \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 54.1+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "categorical_features=[feature for feature in df.columns if df[feature].dtypes=='O']\r\n",
    "categorical_features"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[' Class variable']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "lb = LabelEncoder()\r\n",
    "\r\n",
    "for i in categorical_features:\r\n",
    "    df[i] = lb.fit_transform(df[i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Triceps skin fold thickness</th>\n",
       "      <th>2-Hour serum insulin</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age (years)</th>\n",
       "      <th>Class variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Number of times pregnant   Plasma glucose concentration  \\\n",
       "0                            6                            148   \n",
       "1                            1                             85   \n",
       "2                            8                            183   \n",
       "3                            1                             89   \n",
       "4                            0                            137   \n",
       "..                         ...                            ...   \n",
       "763                         10                            101   \n",
       "764                          2                            122   \n",
       "765                          5                            121   \n",
       "766                          1                            126   \n",
       "767                          1                             93   \n",
       "\n",
       "      Diastolic blood pressure   Triceps skin fold thickness  \\\n",
       "0                           72                            35   \n",
       "1                           66                            29   \n",
       "2                           64                             0   \n",
       "3                           66                            23   \n",
       "4                           40                            35   \n",
       "..                         ...                           ...   \n",
       "763                         76                            48   \n",
       "764                         70                            27   \n",
       "765                         72                            23   \n",
       "766                         60                             0   \n",
       "767                         70                            31   \n",
       "\n",
       "      2-Hour serum insulin   Body mass index   Diabetes pedigree function  \\\n",
       "0                        0              33.6                        0.627   \n",
       "1                        0              26.6                        0.351   \n",
       "2                        0              23.3                        0.672   \n",
       "3                       94              28.1                        0.167   \n",
       "4                      168              43.1                        2.288   \n",
       "..                     ...               ...                          ...   \n",
       "763                    180              32.9                        0.171   \n",
       "764                      0              36.8                        0.340   \n",
       "765                    112              26.2                        0.245   \n",
       "766                      0              30.1                        0.349   \n",
       "767                      0              30.4                        0.315   \n",
       "\n",
       "      Age (years)   Class variable  \n",
       "0              50                1  \n",
       "1              31                0  \n",
       "2              32                1  \n",
       "3              21                0  \n",
       "4              33                1  \n",
       "..            ...              ...  \n",
       "763            63                0  \n",
       "764            27                0  \n",
       "765            30                0  \n",
       "766            47                1  \n",
       "767            23                0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df.columns.to_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.tolist of Index([' Number of times pregnant', ' Plasma glucose concentration',\n",
       "       ' Diastolic blood pressure', ' Triceps skin fold thickness',\n",
       "       ' 2-Hour serum insulin', ' Body mass index',\n",
       "       ' Diabetes pedigree function', ' Age (years)', ' Class variable'],\n",
       "      dtype='object')>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#split data into inputs and targets\r\n",
    "X = df.drop(columns = [' Class variable'])\r\n",
    "y = df[' Class variable']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "#split data into train and test sets\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Boosting**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "ada_clf = AdaBoostClassifier(learning_rate = 0.02, n_estimators = 5000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "ada_clf.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.02, n_estimators=5000)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Evaluation on Testing Data\r\n",
    "print(confusion_matrix(y_test, ada_clf.predict(X_test)))\r\n",
    "print(accuracy_score(y_test, ada_clf.predict(X_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[125  25]\n",
      " [ 38  43]]\n",
      "0.7272727272727273\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "plot_confusion_matrix(ada_clf, X_test, y_test)\r\n",
    "plt.title(\"Confusion matrix of ADA Boosting\")\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Bagging**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from sklearn import tree\r\n",
    "clftree = tree.DecisionTreeClassifier()\r\n",
    "from sklearn.ensemble import BaggingClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "bag_clf = BaggingClassifier(base_estimator = clftree, n_estimators = 500,\r\n",
    "                            bootstrap = True, n_jobs = 1, random_state = 42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "bag_clf.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=500,\n",
       "                  n_jobs=1, random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Evaluation on Testing Data\r\n",
    "print(confusion_matrix(y_test, bag_clf.predict(X_test)))\r\n",
    "print(accuracy_score(y_test, bag_clf.predict(X_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[123  27]\n",
      " [ 33  48]]\n",
      "0.7402597402597403\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Evaluation on Training Data\r\n",
    "print(confusion_matrix(y_train, bag_clf.predict(X_train)))\r\n",
    "print(accuracy_score(y_train, bag_clf.predict(X_train)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[350   0]\n",
      " [  0 187]]\n",
      "1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "plot_confusion_matrix(bag_clf, X_test, y_test)\r\n",
    "plt.title(\"Confusion matrix of Bagging Boosting\")\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAHHCAYAAAC4M/EEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHG0lEQVR4nO3deVhU5dsH8O8MwrCDuACjCCjmvqVFpLkURpr7Fr5aQC6VuZtbpeJeWmmauSdqWpmVv7QycSUTNxQzFxTFDQRSBARlm3neP4jJcVBnmIFh5nw/13UunbPes3HP/TzPOUcmhBAgIiIiqyU3dwBERERUvpjsiYiIrByTPRERkZVjsiciIrJyTPZERERWjsmeiIjIyjHZExERWTkmeyIiIivHZE9ERGTlmOwt1MWLF/Hyyy/Dzc0NMpkM27ZtM+n+r1y5AplMhqioKJPu1xr4+fkhPDy8wo+bk5ODoUOHwsvLCzKZDGPHjq3wGEwtKioKMpkMV65cMXcoFiU8PBx+fn7mDoMsCJO9ES5duoS33noLdevWhb29PVxdXdG2bVt8/vnnuH//frkeOywsDKdPn8bcuXOxceNGtGnTplyPZ43Onj2LyMhIi0k08+bNQ1RUFN555x1s3LgRr7/++iPX9fPzg0wm00z29vaoX78+Jk6ciIyMjAqMuvKKjIzUeo3kcjm8vb3RrVs3HD582NzhISUlBZGRkYiPjzd3KGQFZLw2ftn88ssv6N+/PxQKBd544w00bdoUBQUFOHjwIH744QeEh4dj1apV5XLs+/fvw9HRER988AHmzJlTLscQQiA/Px+2trawsbEpl2OY29atW9G/f3/s27cPHTt21Hu7/Px8yOVy2Nrall9wpXjuuedQpUoVHDx48Inr+vn5oWrVqpgwYQIAIC8vD3FxcVizZg1atWqFo0ePlne4elGpVCgsLIRCoYBMJqvQY0dGRmLmzJlYvnw5nJ2doVarcf36daxevRopKSk4evQoWrZsWaExPej48eN45plnsG7dOp2WpMLCQqjVaigUCvMERxanirkDsERJSUkIDQ2Fr68v9u7dC29vb82yd999F4mJifjll1/K7fj//PMPAMDd3b3cjlFSDVIxIQTy8vLg4OBgtj+w6enpaNy4sd7r16pVC4MHD9Y8Hjp0KJydnfHJJ5/g4sWLqF+/fnmEaRAbGxuz/5js168fqlevrnncq1cvNG3aFN9//71Zk/3jVPQPTbJ8bMYvgwULFiAnJwdr167VSvQlAgICMGbMGM3joqIizJ49G/Xq1YNCoYCfnx/ef/995Ofna23n5+eHbt264eDBg3j22Wdhb2+PunXrYsOGDZp1IiMj4evrCwCYOHEiZDKZpu/uUf14Jc2VD4qOjka7du3g7u4OZ2dnNGjQAO+//75m+aP67Pfu3YsXXngBTk5OcHd3R8+ePXHu3LlSj5eYmIjw8HC4u7vDzc0NERERuHfv3qNf2H917NgRTZs2xV9//YUOHTrA0dERAQEB2Lp1KwDgwIEDCAwMhIODAxo0aIDdu3drbX/16lWMGDECDRo0gIODA6pVq4b+/ftrNddHRUWhf//+AIBOnTppmnL3798P4L/34vfff0ebNm3g4OCAlStXapaVVFpCCHTq1Ak1atRAenq6Zv8FBQVo1qwZ6tWrh9zc3Mc+3/T0dAwZMgSenp6wt7dHixYtsH79es3y/fv3QyaTISkpCb/88osm1rJ0P3h5eQEAqlT573f+X3/9hfDwcE13lJeXF958803cvn1bZ/v9+/ejTZs2sLe3R7169bBy5cpSP1/379/H6NGjUb16dbi4uKBHjx5ITk6GTCZDZGSkZr3S+uz1+R48GHuHDh3g4OCA2rVrY86cOVi3bp1R4wBKe42AJ79PJXJzczFhwgT4+PhAoVCgQYMG+OSTT/BwI+rjvoP79+/HM888AwCIiIjQvOcl38eHv+sl39dPPvkEq1at0vyteeaZZ3Ds2DGdGL///ns0btwY9vb2aNq0KX766SeOA7ByrOzLYPv27ahbty6ef/55vdYfOnQo1q9fj379+mHChAk4cuQI5s+fj3PnzuGnn37SWjcxMRH9+vXDkCFDEBYWhq+++grh4eFo3bo1mjRpgj59+sDd3R3jxo3DwIED0bVrVzg7OxsU/5kzZ9CtWzc0b94cs2bNgkKhQGJiIv7888/Hbrd792506dIFdevWRWRkJO7fv4+lS5eibdu2OHHihM4figEDBsDf3x/z58/HiRMnsGbNGtSsWRMff/zxE2O8c+cOunXrhtDQUPTv3x/Lly9HaGgoNm3ahLFjx+Ltt9/G//3f/2HhwoXo168frl+/DhcXFwDAsWPHcOjQIYSGhqJ27dq4cuUKli9fjo4dO+Ls2bNwdHRE+/btMXr0aCxZsgTvv/8+GjVqBACafwEgISEBAwcOxFtvvYVhw4ahQYMGOnHKZDJ89dVXaN68Od5++238+OOPAIAZM2bgzJkz2L9/P5ycnB75PO/fv4+OHTsiMTERI0eOhL+/P77//nuEh4cjMzMTY8aMQaNGjbBx40aMGzcOtWvX1jTN16hR47GvYWFhIW7dugWguBn/5MmT+Oyzz9C+fXv4+/tr1ouOjsbly5cREREBLy8vnDlzBqtWrcKZM2dw+PBhTSI/efIkXnnlFXh7e2PmzJlQqVSYNWtWqXGEh4djy5YteP311/Hcc8/hwIEDePXVVx8b74Oe9D0AgOTkZM0PtalTp8LJyQlr1qwxuOWlZAyDWq1GcnIyZs+eDXt7ewwYMECzjj7vE1D8469Hjx7Yt28fhgwZgpYtW+L333/HxIkTkZycjEWLFgF48newUaNGmDVrFqZPn47hw4fjhRdeAIAn/s3ZvHkz7t69i7feegsymQwLFixAnz59cPnyZU1rwC+//ILXXnsNzZo1w/z583Hnzh0MGTIEtWrVMuh1IwsjyCBZWVkCgOjZs6de68fHxwsAYujQoVrz33vvPQFA7N27VzPP19dXABAxMTGaeenp6UKhUIgJEyZo5iUlJQkAYuHChVr7DAsLE76+vjoxzJgxQzz4Vi9atEgAEP/8888j4y45xrp16zTzWrZsKWrWrClu376tmXfq1Ckhl8vFG2+8oXO8N998U2ufvXv3FtWqVXvkMUt06NBBABCbN2/WzDt//rwAIORyuTh8+LBm/u+//64T571793T2GRsbKwCIDRs2aOZ9//33AoDYt2+fzvol78XOnTtLXRYWFqY1b+XKlQKA+Prrr8Xhw4eFjY2NGDt27BOf6+LFizXblSgoKBBBQUHC2dlZZGdnax331VdffeI+H4z/4alt27bi1q1bWuuW9np98803Op/F7t27C0dHR5GcnKyZd/HiRVGlShWtz1dcXJwAoPP8w8PDBQAxY8YMzbx169YJACIpKUkn9id9D0aNGiVkMpk4efKkZt7t27eFh4eHzj5LU/I5fXhyd3fXed/1fZ+2bdsmAIg5c+Zobd+vXz8hk8lEYmKiEEK/7+CxY8d0PtslHv6ul3xfq1WrJjIyMjTz//e//wkAYvv27Zp5zZo1E7Vr1xZ3797VzNu/f78AUOrfD7IObMY3UHZ2NgBoqsgn+fXXXwEA48eP15pfUp093LffuHFjza94oLh6a9CgAS5fvlzmmB9W0tf/v//9D2q1Wq9tbt68ifj4eISHh8PDw0Mzv3nz5ujcubPmeT7o7bff1nr8wgsv4Pbt25rX8HGcnZ0RGhqqedygQQO4u7ujUaNGCAwM1Mwv+f+Dr4+Dg4Pm/4WFhbh9+zYCAgLg7u6OEydO6PFsi/n7+yMkJESvdYcPH46QkBCMGjUKr7/+OurVq4d58+Y9cbtff/0VXl5eGDhwoGaera0tRo8ejZycHBw4cEDveB8WGBiI6OhoREdHY8eOHZg7dy7OnDmDHj16aJ0t8uDrlZeXh1u3buG5554DAM3rpVKpsHv3bvTq1QtKpVKzfkBAALp06aJ13J07dwIARowYoTV/1KhReseuz/dg586dCAoK0upX9/DwwKBBg/Q+DgD88MMPiI6Oxq5du7Bu3To89dRT6Nu3Lw4dOqRZR9/36ddff4WNjQ1Gjx6tdYwJEyZACIHffvsNQNm+g/p47bXXULVqVc3jktew5HVLSUnB6dOn8cYbb2i1CHbo0AHNmjUzWRxU+TDZG8jV1RUAcPfuXb3Wv3r1KuRyOQICArTme3l5wd3dHVevXtWaX6dOHZ19VK1aFXfu3CljxLpee+01tG3bFkOHDoWnpydCQ0OxZcuWx/7RKYmztKbsRo0a4datWzp90w8/l5I/Qvo8l9q1a+v0A7u5ucHHx0dn3sP7vH//PqZPn67pM61evTpq1KiBzMxMZGVlPfHYJR5s6tbH2rVrce/ePVy8eBFRUVFaSfRRrl69ivr160Mu1/4qlnQnPPz5MET16tURHByM4OBgvPrqq3j//fexZs0aHDp0CGvWrNGsl5GRgTFjxsDT0xMODg6oUaOG5rmXvF7p6em4f/++zucYgM68ks/8w69fads+ij7fg6tXr+oVz5O0b98ewcHB6Ny5M8LDw7Fnzx64uLho/TjR9326evUqlEqlTjHw8Hpl+Q7q40nfuZLjm+J1I8vCZG8gV1dXKJVK/P333wZtp+9pRY8amSz0OEPyUcdQqVRajx0cHBATE4Pdu3fj9ddfx19//YXXXnsNnTt31lnXGMY8l0dtq88+R40ahblz52LAgAHYsmULdu3ahejoaFSrVs2gP6b6JOsH7d+/XzPo8vTp0wZtW1FeeuklAEBMTIxm3oABA7B69WrNmINdu3ZpqnNTVp2GMOazYyxnZ2cEBgbixIkTTxxcWVbl9R005+tGlRuTfRl069YNly5dQmxs7BPX9fX1hVqtxsWLF7Xmp6WlITMzUzOy3hSqVq2KzMxMnfmlVYdyuRwvvfQSPvvsM5w9exZz587F3r17sW/fvlL3XRJnQkKCzrLz58+jevXqjx2IVpG2bt2KsLAwfPrpp+jXrx86d+6Mdu3a6bw2pjyv++bNmxg1ahRefvlldOvWDe+9955eVbmvry8uXryok1TPnz+vWW5KRUVFAIqvxgcUV3x79uzBlClTMHPmTPTu3RudO3dG3bp1tbarWbMm7O3tkZiYqLPPh+eVfOaTkpIeu56xfH199YqnLB5+nfR9n3x9fZGSkqLT8lfa+/mk72B5XHeg5Pjl9bpR5cVkXwaTJk2Ck5MThg4dirS0NJ3lly5dwueffw4A6Nq1KwBg8eLFWut89tlnAGDQCOUnqVevHrKysvDXX39p5t28eVNnxH9pV1Ar6fd8+HTAEt7e3mjZsiXWr1+vlTT//vtv7Nq1S/M8KwMbGxudSmbp0qU6FVPJj5PSfiAZatiwYVCr1Vi7di1WrVqFKlWqYMiQIU+sqLp27YrU1FR89913mnlFRUVYunQpnJ2d0aFDB6Nje9D27dsBAC1atADwXyX4cJwPf15tbGwQHByMbdu2ISUlRTM/MTFR0w9domScw5dffqk1f+nSpcY/gYeOExsbq3WFuYyMDGzatMmo/WZkZODQoUPw8vJCzZo1Aej/PnXt2hUqlQpffPGF1j4XLVoEmUymGd+gz3fQlJ/PEkqlEk2bNsWGDRs0P2SA4tNZK2trFJkGT70rg3r16mHz5s147bXX0KhRI60r6B06dEhzSg5Q/Ec1LCwMq1atQmZmJjp06ICjR49i/fr16NWrFzp16mSyuEJDQzF58mT07t0bo0ePxr1797B8+XI89dRTWgPTZs2ahZiYGLz66qvw9fVFeno6vvzyS9SuXRvt2rV75P4XLlyILl26ICgoCEOGDNGceufm5qZ17rS5devWDRs3boSbmxsaN26M2NhY7N69G9WqVdNar2XLlrCxscHHH3+MrKwsKBQKvPjii5o/8Ppat24dfvnlF0RFRaF27doAihPb4MGDsXz5cp2Bag8aPnw4Vq5cifDwcMTFxcHPzw9bt27Fn3/+icWLF+s9ELQ0ycnJ+PrrrwEUn/d/6tQprFy5EtWrV9f0R7u6uqJ9+/ZYsGABCgsLUatWLezatUunKgeKr5+wa9cutG3bFu+8844mqTVt2lQr4bZu3Rp9+/bF4sWLcfv2bc2pdxcuXABguop10qRJ+Prrr9G5c2eMGjVKc+pdnTp1kJGRofdxtm7dCmdnZwghkJKSgrVr1+LOnTtYsWKFZh/6vk/du3dHp06d8MEHH+DKlSto0aIFdu3ahf/9738YO3Ys6tWrB0C/72C9evXg7u6OFStWwMXFBU5OTggMDDR4LMnD5s2bh549e6Jt27aIiIjAnTt3NO/jgz8AyMqY6zQAa3DhwgUxbNgw4efnJ+zs7ISLi4to27atWLp0qcjLy9OsV1hYKGbOnCn8/f2Fra2t8PHxEVOnTtVaR4hHn1rVoUMH0aFDB83jR516J4QQu3btEk2bNhV2dnaiQYMG4uuvv9Y59W7Pnj2iZ8+eQqlUCjs7O6FUKsXAgQPFhQsXdI7x8Gk/u3fvFm3bthUODg7C1dVVdO/eXZw9e1ZrnZLjPXxaUWmnWZWmQ4cOokmTJjrzH/X6ABDvvvuu5vGdO3dERESEqF69unB2dhYhISHi/PnzpZ4yt3r1alG3bl1hY2OjdRre405ze3A/169fF25ubqJ79+466/Xu3Vs4OTmJy5cvP/b5pqWlaeK1s7MTzZo1K/V0K2NOvZPL5aJmzZpi4MCBmtO/Sty4cUP07t1buLu7Czc3N9G/f3+RkpKic5qcEMWfnVatWgk7OztRr149sWbNGjFhwgRhb2+vtV5ubq549913hYeHh3B2dha9evUSCQkJAoD46KOPNOs96tQ7fb4HQghx8uRJ8cILLwiFQiFq164t5s+fL5YsWSIAiNTU1Me+RqWdeufk5CSCgoLEli1bdNbX9326e/euGDdunFAqlcLW1lbUr19fLFy4UKjVaq3X8UnfQSGKT51r3Lix5vTGkuM96tS70v4mlPY+fvvtt6Jhw4ZCoVCIpk2bip9//ln07dtXNGzY8LGvGVkuXhufiIzSq1cvnDlzRmdcysPi4+PRqlUrfP311wafHmeIsWPHYuXKlcjJyTH7pXgtScuWLVGjRg1ER0ebOxQqB+yzJyK9PXw3x4sXL+LXX3/VuZFQaXd9XLx4MeRyOdq3b19u8dy+fRsbN25Eu3btmOgfobCwUDMAscT+/ftx6tQpg24IRZaFffZEpLe6detqrqN/9epVLF++HHZ2dpg0aZLWegsWLEBcXBw6deqEKlWq4LfffsNvv/2G4cOH61wrwRhBQUHo2LEjGjVqhLS0NKxduxbZ2dmYNm2ayY5hbZKTkxEcHIzBgwdDqVTi/PnzWLFiBby8vHQuhEVWxNz9CERkOcLDw4Wvr69QKBTC1dVVhISEiLi4OJ31du3aJdq2bSuqVq0qbG1tRb169URkZKQoLCw0aTxTp04V9evXFw4ODsLR0VG0a9dOREdHm/QY1iYzM1MMGDBA1KpVS9jZ2YmqVauKfv366YzlIOvCPnsiIiIrxz57IiIiK8dkT0REZOUseoCeWq1GSkoKXFxcyuXSkkREVL6EELh79y6USqXOjYZMKS8vDwUFBUbvx87ODvb29iaIqGJZdLJPSUkx6cheIiIyj+vXr2uuQGlqeXl58Pd1Rmq68Tf68vLyQlJSksUlfItO9iWXqLx6wg+uzuyRIOvU+yneZ5ysVxEKcRC/GnVp6CcpKChAaroKV+P84OpS9lyRfVcN39ZXUFBQwGRfkUqa7l2d5Ua9gUSVWRWZrblDICo//54PVhFdsc4uMji7lP04alhud7FFJ3siIiJ9qYQaKiNONlcJ9ZNXqqSY7ImISBLUEFCj7NnemG3NjW3fREREVo6VPRERSYIaahjTEG/c1ubFyp6IiCRBJYTRkyFiYmLQvXt3KJVKyGQybNu2TbOssLAQkydPRrNmzeDk5ASlUok33ngDKSkpWvvIyMjAoEGD4OrqCnd3dwwZMgQ5OTkGP3cmeyIionKQm5uLFi1aYNmyZTrL7t27hxMnTmDatGk4ceIEfvzxRyQkJKBHjx5a6w0aNAhnzpxBdHQ0duzYgZiYGAwfPtzgWNiMT0REklDRA/S6dOmCLl26lLrMzc0N0dHRWvO++OILPPvss7h27Rrq1KmDc+fOYefOnTh27BjatGkDAFi6dCm6du2KTz75BEqlUu9YWNkTEZEkqCGgMmIq79H4WVlZkMlkcHd3BwDExsbC3d1dk+gBIDg4GHK5HEeOHDFo36zsiYiIDJCdna31WKFQQKFQGLXPvLw8TJ48GQMHDoSrqysAIDU1FTVr1tRar0qVKvDw8EBqaqpB+2dlT0REklDSjG/MBAA+Pj5wc3PTTPPnzzcqrsLCQgwYMABCCCxfvtwUT1UHK3siIpKEsoyof3h7oPimPSXVNwCjqvqSRH/16lXs3btXa79eXl5IT0/XWr+oqAgZGRnw8vIy6Dis7ImIiAzg6uqqNZU12Zck+osXL2L37t2oVq2a1vKgoCBkZmYiLi5OM2/v3r1Qq9UIDAw06Fis7ImISBLU/07GbG+InJwcJCYmah4nJSUhPj4eHh4e8Pb2Rr9+/XDixAns2LEDKpVK0w/v4eEBOzs7NGrUCK+88gqGDRuGFStWoLCwECNHjkRoaKhBI/EBJnsiIpKIklH1xmxviOPHj6NTp06ax+PHjwcAhIWFITIyEj///DMAoGXLllrb7du3Dx07dgQAbNq0CSNHjsRLL70EuVyOvn37YsmSJQbHzmRPRESSoBIw8q53hq3fsWNHiMeMEXjcshIeHh7YvHmzYQcuBfvsiYiIrBwreyIikoSK7rOvTJjsiYhIEtSQQQWZUdtbKjbjExERWTlW9kREJAlqUTwZs72lYrInIiJJUBnZjG/MtubGZnwiIiIrx8qeiIgkQcqVPZM9ERFJglrIoBZGjMY3YltzYzM+ERGRlWNlT0REksBmfCIiIiunghwqIxq0VSaMpaIx2RMRkSQII/vsBfvsiYiIqLJiZU9ERJLAPnsiIiIrpxJyqIQRffYWfLlcNuMTERFZOVb2REQkCWrIoDaixlXDckt7JnsiIpIEKffZsxmfiIjIyrGyJyIiSTB+gB6b8YmIiCq14j57I26Ew2Z8IiIiqqxY2RMRkSSojbw2PkfjExERVXLssyciIrJyasgle549++yJiIisHCt7IiKSBJWQQWXEbWqN2dbcmOyJiEgSVEYO0FOxGZ+IiIgqK1b2REQkCWohh9qI0fhqjsYnIiKq3NiMT0RERFaLlT0REUmCGsaNqFebLpQKx2RPRESSYPxFdSy3MdxyIyciIiK9sLInIiJJMP7a+JZbHzPZExGRJEj5fvZM9kREJAlSruwtN3IiIiLSCyt7IiKSBOMvqmO59TGTPRERSYJayKA25jx7C77rneX+TCEiIiK9sLInIiJJUBvZjG/JF9VhsiciIkkw/q53lpvsLTdyIiIi0gsreyIikgQVZFAZcWEcY7Y1NyZ7IiKSBDbjExERkdViZU9ERJKggnFN8SrThVLhmOyJiEgSpNyMz2RPRESSwBvhEBERkdViZU9ERJIgjLyfveCpd0RERJUbm/GJiIjIarGyJyIiSZDyLW6Z7ImISBJURt71zphtzc1yIyciIiK9sLInIiJJYDM+ERGRlVNDDrURDdrGbGtulhs5ERER6YWVPRERSYJKyKAyoinemG3NjcmeiIgkgX32REREVk4Yedc7wSvoERERUWXFZE9ERJKggszoyRAxMTHo3r07lEolZDIZtm3bprVcCIHp06fD29sbDg4OCA4OxsWLF7XWycjIwKBBg+Dq6gp3d3cMGTIEOTk5Bj93JnsiIpIEtfiv375sk2HHy83NRYsWLbBs2bJSly9YsABLlizBihUrcOTIETg5OSEkJAR5eXmadQYNGoQzZ84gOjoaO3bsQExMDIYPH27wc2efPRERUTno0qULunTpUuoyIQQWL16MDz/8ED179gQAbNiwAZ6enti2bRtCQ0Nx7tw57Ny5E8eOHUObNm0AAEuXLkXXrl3xySefQKlU6h0Lkz3h9GEnfP9lTVw87YiMNFvMWJuE57tkAQCKCoGoj71xbK8rbl61g5OrGq1euIsh76egmleRZh8zwvxx6YwDMm9XgYubqnidD7TXIaosXhuZhrZds+ATkI+CPDnOHnfE2rneuHHJHgDgWbsAG46eK3XbOcN98ccO9wqMlkxFbeQAPWO2fVhSUhJSU1MRHBysmefm5obAwEDExsYiNDQUsbGxcHd31yR6AAgODoZcLseRI0fQu3dvvY9XKZrxly1bBj8/P9jb2yMwMBBHjx41d0iSkndPjrpN7mPkvBs6y/Lvy5F42hH/NzYNy36/gOlrknDjkgIzwutqrdeibQ4+WHkFa/84hw9XJyHligKzh/lX1FMgMkjzoFxsj6qOsd3qY2poXdhUEZj3zWUoHFQAgH9SbBHaorHWtGGhJ+7lyHFsr4uZo6eyUkNm9AQA2dnZWlN+fr7BsaSmpgIAPD09teZ7enpqlqWmpqJmzZpay6tUqQIPDw/NOvoye2X/3XffYfz48VixYgUCAwOxePFihISEICEhQedJUvl45sW7eObFu6Uuc3JV46PvLmnNe3fuDYzu2gDpN2xRs3YhAKDP8H80yz1rF+K1kWmY+aY/igqBKrblFztRWXwwSPvH6qdj62DL32dQv/l9/H3EGWq1DHf+0f7gPt8lCzHb3ZF3z6YiQ6VKyMfHR+vxjBkzEBkZaZ5g9GT2yv6zzz7DsGHDEBERgcaNG2PFihVwdHTEV199Ze7Q6BFys20gkwk4ualKXZ59xwZ7f6yKxm1ymejJIji5Fn+W72aWnsgDmt1DQNM8/P6NR0WGRSZWcgU9YyYAuH79OrKysjTT1KlTDY7Fy8sLAJCWlqY1Py0tTbPMy8sL6enpWsuLioqQkZGhWUdfZk32BQUFiIuL0+qzkMvlCA4ORmxsrBkjo0cpyJNh7VwlOva6AycXtdayNXO80aNeM/Rv0gz/pNghcl2SmaIk0p9MJvD2zGT8fdQRVxMcSl3nlYEZuHpBgbPHnSo4OjKlkj57YyYAcHV11ZoUCoXBsfj7+8PLywt79uzRzMvOzsaRI0cQFBQEAAgKCkJmZibi4uI06+zduxdqtRqBgYEGHc+syf7WrVtQqVSP7bN4UH5+vk5fCVWcokJg7lt+gABGfaTbv9//nXR8uesC5n2TCLlcYOGYOhAGnqpCVNFGzkuGb8M8zH/Ht9TldvZqdOp9h1U9GSwnJwfx8fGIj48HUDwoLz4+HteuXYNMJsPYsWMxZ84c/Pzzzzh9+jTeeOMNKJVK9OrVCwDQqFEjvPLKKxg2bBiOHj2KP//8EyNHjkRoaKhBI/GBStBnb4j58+dj5syZ5g5DkkoSfVqyHRZsSdSp6gHArZoKbtVUqF0vH3XqX8XgNk1wLs4RjdvcM0PERE/27twbCOycjQm96+HWTbtS13nh1UwoHAR2f89kb+nUMPLa+AZeVOf48ePo1KmT5vH48eMBAGFhYYiKisKkSZOQm5uL4cOHIzMzE+3atcPOnTthb2+v2WbTpk0YOXIkXnrpJcjlcvTt2xdLliwxOHazJvvq1avDxsbmsX0WD5o6darmxQKKmzweHihBpleS6JOTFFiwNRGuHqX31T9I/PtboLDA7MNCiEoh8O7cZDz/ShYm9gtA2vVHN8OGDMzA4V2uyMqwqNqISiEeGFFf1u0N0bFjR4jHNG/KZDLMmjULs2bNeuQ6Hh4e2Lx5s0HHLY1ZP712dnZo3bo19uzZo2m2UKvV2LNnD0aOHKmzvkKhKFPfCD3e/Vw5UpL+e11Tr9vh0t8OcHEvgodnIWYP80fiaQfM2nAZapUMGenFHxsXdxVs7QTOn3BEQrwjmj6bC2f3Ity8osD6BV7w9stHo9a55npaRI80cl4yOvW+g8gIf9zPkaNqjeKzSnLv2qAg778fqEq/fDR7LhfTBvM0UmvAu96Z0fjx4xEWFoY2bdrg2WefxeLFi5Gbm4uIiAhzhyYZF045YlK/AM3jlZG1AACdB2Rg8IRUHN7lBgAY0bmh1nYLtiaixfM5UDio8edvbtj4qRfy7snhUbMQbTrdxQdjrsJOwU57qny6h98GAHzyo/ZppZ+M9UH0lv+a60NCM3Drpi3iDvDcerJsZk/2r732Gv755x9Mnz4dqampaNmyJXbu3KkzaI/KT4vnc/B7Svwjlz9uGQD4N8rDgu8vPXYdosokRNlCr/XWfeSNdR95l3M0VFEq0xX0KprZkz0AjBw5stRmeyIiIlORcjO+5f5MISIiIr1UisqeiIiovKmNHI1vzLbmxmRPRESSwGZ8IiIislqs7ImISBKkXNkz2RMRkSRIOdmzGZ+IiMjKsbInIiJJkHJlz2RPRESSIGDc6XOWfPFvJnsiIpIEKVf27LMnIiKycqzsiYhIEqRc2TPZExGRJEg52bMZn4iIyMqxsiciIkmQcmXPZE9ERJIghAzCiIRtzLbmxmZ8IiIiK8fKnoiIJIH3syciIrJyUu6zZzM+ERGRlWNlT0REkiDlAXpM9kREJAlSbsZnsiciIkmQcmXPPnsiIiIrx8qeiIgkQRjZjG/JlT2TPRERSYIAIIRx21sqNuMTERFZOVb2REQkCWrIIOMV9IiIiKwXR+MTERGR1WJlT0REkqAWMsh4UR0iIiLrJYSRo/EteDg+m/GJiIisHCt7IiKSBCkP0GOyJyIiSWCyJyIisnJSHqDHPnsiIiIrx8qeiIgkQcqj8ZnsiYhIEoqTvTF99iYMpoKxGZ+IiMjKsbInIiJJ4Gh8IiIiKydg3D3pLbgVn834RERE1o6VPRERSQKb8YmIiKydhNvxmeyJiEgajKzsYcGVPfvsiYiIrBwreyIikgReQY+IiMjKSXmAHpvxiYiIrBwreyIikgYhM26QnQVX9kz2REQkCVLus2czPhERkZVjZU9ERNLAi+o83s8//6z3Dnv06FHmYIiIiMqLlEfj65Xse/XqpdfOZDIZVCqVMfEQERGRiemV7NVqdXnHQUREVP4suCneGEb12efl5cHe3t5UsRAREZUbKTfjGzwaX6VSYfbs2ahVqxacnZ1x+fJlAMC0adOwdu1akwdIRERkEsIEk4UyONnPnTsXUVFRWLBgAezs7DTzmzZtijVr1pg0OCIiIjKewcl+w4YNWLVqFQYNGgQbGxvN/BYtWuD8+fMmDY6IiMh0ZCaYLJPBffbJyckICAjQma9Wq1FYWGiSoIiIiExOwufZG1zZN27cGH/88YfO/K1bt6JVq1YmCYqIiMjSqVQqTJs2Df7+/nBwcEC9evUwe/ZsiAeuuyuEwPTp0+Ht7Q0HBwcEBwfj4sWLJo/F4Mp++vTpCAsLQ3JyMtRqNX788UckJCRgw4YN2LFjh8kDJCIiMokKruw//vhjLF++HOvXr0eTJk1w/PhxREREwM3NDaNHjwYALFiwAEuWLMH69evh7++PadOmISQkBGfPnjXp2W4GV/Y9e/bE9u3bsXv3bjg5OWH69Ok4d+4ctm/fjs6dO5ssMCIiIpMqueudMZMBDh06hJ49e+LVV1+Fn58f+vXrh5dffhlHjx4tDkcILF68GB9++CF69uyJ5s2bY8OGDUhJScG2bdtM+tTLdCOcF154AdHR0UhPT8e9e/dw8OBBvPzyyyYNjIiIyJI9//zz2LNnDy5cuAAAOHXqFA4ePIguXboAAJKSkpCamorg4GDNNm5ubggMDERsbKxJYynzRXWOHz+Oc+fOASjux2/durXJgiIiIjI1U93iNjs7W2u+QqGAQqHQWX/KlCnIzs5Gw4YNYWNjA5VKhblz52LQoEEAgNTUVACAp6en1naenp6aZaZicLK/ceMGBg4ciD///BPu7u4AgMzMTDz//PP49ttvUbt2bZMGSEREZBIm6rP38fHRmj1jxgxERkbqrL5lyxZs2rQJmzdvRpMmTRAfH4+xY8dCqVQiLCzMiEAMZ3CyHzp0KAoLC3Hu3Dk0aNAAAJCQkICIiAgMHToUO3fuNHmQRERElcX169fh6uqqeVxaVQ8AEydOxJQpUxAaGgoAaNasGa5evYr58+cjLCwMXl5eAIC0tDR4e3trtktLS0PLli1NGrPBffYHDhzA8uXLNYkeABo0aIClS5ciJibGpMERERGZjIkG6Lm6umpNj0r29+7dg1yunWZtbGw0N5fz9/eHl5cX9uzZo1menZ2NI0eOICgoyKRP3eDK3sfHp9SL56hUKiiVSpMERUREZGoyUTwZs70hunfvjrlz56JOnTpo0qQJTp48ic8++wxvvvlm8f5kMowdOxZz5sxB/fr1NafeKZVKvW8try+Dk/3ChQsxatQoLFu2DG3atAFQPFhvzJgx+OSTT0waHBERkclU8Hn2S5cuxbRp0zBixAikp6dDqVTirbfewvTp0zXrTJo0Cbm5uRg+fDgyMzPRrl077Ny50+R3lJUJ8eSxiVWrVoVM9t/5hbm5uSgqKkKVKsW/FUr+7+TkhIyMDJMG+DjZ2dlwc3PDnQt14epSprMIiSq9EGVLc4dAVG6KRCH243/IysrS6gc3pZJc4bN4FuQOZU+i6vt5uD52ernGWl70quwXL15czmEQERGVszJcGEdnewulV7Kv6FMEiIiITE7CN8Ip80V1ACAvLw8FBQVa8yytaYOIiMjaGdzRnZubi5EjR6JmzZpwcnJC1apVtSYiIqJKSZhgslAGJ/tJkyZh7969WL58ORQKBdasWYOZM2dCqVRiw4YN5REjERGR8SSc7A1uxt++fTs2bNiAjh07IiIiAi+88AICAgLg6+uLTZs2aa75S0RERJWDwZV9RkYG6tatC6C4f77kVLt27drxCnpERFR5VfAtbisTg5N93bp1kZSUBABo2LAhtmzZAqC44i+5MQ4REVFlU3IFPWMmS2Vwso+IiMCpU6cAFN++b9myZbC3t8e4ceMwceJEkwdIRERExjG4z37cuHGa/wcHB+P8+fOIi4tDQEAAmjdvbtLgiIiITIbn2Zedr68vfH19TRELERERlQO9kv2SJUv03uHo0aPLHAwREVF5kcHIu96ZLJKKp1eyX7RokV47k8lkTPZERESVjF7JvmT0fWXVr92LqCK3M3cYROWi4BV2k5H1KirMA3b/r2IOxhvhEBERWTkJD9DjTeCJiIisHCt7IiKSBglX9kz2REQkCcZeBU9SV9AjIiIiy1KmZP/HH39g8ODBCAoKQnJyMgBg48aNOHjwoEmDIyIiMhkJ3+LW4GT/ww8/ICQkBA4ODjh58iTy8/MBAFlZWZg3b57JAyQiIjIJJnv9zZkzBytWrMDq1atha2urmd+2bVucOHHCpMERERGR8QweoJeQkID27dvrzHdzc0NmZqYpYiIiIjI5DtAzgJeXFxITE3XmHzx4EHXr1jVJUERERCZXcgU9YyYLZXCyHzZsGMaMGYMjR45AJpMhJSUFmzZtwnvvvYd33nmnPGIkIiIynoT77A1uxp8yZQrUajVeeukl3Lt3D+3bt4dCocB7772HUaNGlUeMREREZASDk71MJsMHH3yAiRMnIjExETk5OWjcuDGcnZ3LIz4iIiKTkHKffZmvoGdnZ4fGjRubMhYiIqLyw8vl6q9Tp06QyR49SGHv3r1GBURERESmZXCyb9mypdbjwsJCxMfH4++//0ZYWJip4iIiIjItI5vxJVXZL1q0qNT5kZGRyMnJMTogIiKiciHhZnyT3Qhn8ODB+Oqrr0y1OyIiIjIRk93iNjY2Fvb29qbaHRERkWlJuLI3ONn36dNH67EQAjdv3sTx48cxbdo0kwVGRERkSjz1zgBubm5aj+VyORo0aIBZs2bh5ZdfNllgREREZBoGJXuVSoWIiAg0a9YMVatWLa+YiIiIyIQMGqBnY2ODl19+mXe3IyIiyyPha+MbPBq/adOmuHz5cnnEQkREVG5K+uyNmSyVwcl+zpw5eO+997Bjxw7cvHkT2dnZWhMRERFVLnr32c+aNQsTJkxA165dAQA9evTQumyuEAIymQwqlcr0URIREZmCBVfnxtA72c+cORNvv/029u3bV57xEBERlQ+eZ/9kQhQ/yw4dOpRbMERERGR6Bp1697i73REREVVmvKiOnp566qknJvyMjAyjAiIiIioXbMbXz8yZM3WuoEdERESVm0HJPjQ0FDVr1iyvWIiIiMoNm/H1wP56IiKyaBJuxtf7ojolo/GJiIjIsuhd2avV6vKMg4iIqHxJuLI3+Ba3REREloh99kRERNZOwpW9wTfCISIiIsvCyp6IiKRBwpU9kz0REUmClPvs2YxPRERk5VjZExGRNLAZn4iIyLqxGZ+IiIisFit7IiKSBjbjExERWTkJJ3s24xMREVk5VvZERCQJsn8nY7a3VEz2REQkDRJuxmeyJyIiSeCpd0RERGS1WNkTEZE0SLgZn5U9ERFJhzBiKoPk5GQMHjwY1apVg4ODA5o1a4bjx4//F44QmD59Ory9veHg4IDg4GBcvHixzE/vUZjsiYiIysGdO3fQtm1b2Nra4rfffsPZs2fx6aefomrVqpp1FixYgCVLlmDFihU4cuQInJycEBISgry8PJPGwmZ8IiKShIoeoPfxxx/Dx8cH69at08zz9/fX/F8IgcWLF+PDDz9Ez549AQAbNmyAp6cntm3bhtDQ0LIH+xBW9kREJA3GNOGXoSn/559/Rps2bdC/f3/UrFkTrVq1wurVqzXLk5KSkJqaiuDgYM08Nzc3BAYGIjY2tqzPslRM9kRERAbIzs7WmvLz80td7/Lly1i+fDnq16+P33//He+88w5Gjx6N9evXAwBSU1MBAJ6enlrbeXp6apaZCpM9ERFJQkkzvjETAPj4+MDNzU0zzZ8/v9TjqdVqPP3005g3bx5atWqF4cOHY9iwYVixYkUFPuti7LMnIiJpMNGpd9evX4erq6tmtkKhKHV1b29vNG7cWGteo0aN8MMPPwAAvLy8AABpaWnw9vbWrJOWloaWLVsaEaguVvZEREQGcHV11Zoelezbtm2LhIQErXkXLlyAr68vgOLBel5eXtizZ49meXZ2No4cOYKgoCCTxszKnoiIJKGiR+OPGzcOzz//PObNm4cBAwbg6NGjWLVqFVatWlW8P5kMY8eOxZw5c1C/fn34+/tj2rRpUCqV6NWrV9kDLQWTPRERSUMFX0HvmWeewU8//YSpU6di1qxZ8Pf3x+LFizFo0CDNOpMmTUJubi6GDx+OzMxMtGvXDjt37oS9vb0RgepisiciImkww+Vyu3Xrhm7duj1yuUwmw6xZszBr1iwjAnsy9tkTERFZOVb2REQkCVK+xS2TPRERSQPvekdERETWipU9ERFJgkwIyETZy3NjtjU3JnsiIpIGNuMTERGRtWJlT0REksDR+ERERNaOzfhERERkrVjZExGRJLAZn4iIyNpJuBmfyZ6IiCRBypU9++yJiIisHCt7IiKSBjbjExERWT9Lboo3BpvxiYiIrBwreyIikgYhiidjtrdQTPZERCQJHI1PREREVouVPRERSQNH4xMREVk3mbp4MmZ7S8VmfCIiIivHyp50dO1/Ha/2uwFP5X0AwNXLzvhmVV0c/7M6AGDkB2fRKjADHjXykXffBmdPuWPd5/Vx44qTOcMmKpOBXU9heL9j2BrdBMu+CQIAVHW9h7cHHEWbJslwsC/E9VQ3bNrREjFx/maOlowi4WZ8s1b2MTEx6N69O5RKJWQyGbZt22bOcOhft9LssW5pAEYPCsSYQYE4ddQD0xbFo07dHABA4jlXLIpsgrf6PI8PRzwNmUxgzpcnIJdb8DeBJKmB3z/o3uEcLl330Jo/degB+Hhl4YMlnTFkeh/8EeeH6e/sRUCdW2aKlEyhZDS+MZOlMmuyz83NRYsWLbBs2TJzhkEPORpTA8cP1kDKNSckX3PChmUByLtng4bNswAAO3+sjb9PVEX6TQdcOu+KDcsCUNM7DzX/bQkgsgT2ikJ8MHwfPln/Au7m2mktaxqQhp/2NMb5pJq4+Y8rvt7RCjn37PCUL5O9RSs5z96YyUKZtRm/S5cu6NKlizlDoCeQywXadU6DvYMK5/5y01musFehc48U3LzhgFup9maIkKhsxg4+hMN/1cGJs7XwereTWsv+TvREp2cv4/BfPsi5p0DHZy7DzlaF+ARvM0VLZByL6rPPz89Hfn6+5nF2drYZo7FufgF38en6Y7CzU+P+fRvMntAC1y87a5a/2v863hx7EQ6OKlxPcsQH7zyNoiKO9yTL0OnZS6jvewtvz+pZ6vKZy1/EjHf24uelX6OoSIa8giqY/kUwUtJ1f/CS5eBFdSzE/Pnz4ebmppl8fHzMHZLVunHFCSNDn8O4N57Fr9/XxoRZZ+Dzb589AOz7zQujBgZi0pA2SL7miKkf/wVbO5UZIybST42qORg5MBZzV3VEYVHp9c6bvePg7FiACQu74O3ZvfD9rmaY8c5e+NfKqOBoyaSECSYLZVGV/dSpUzF+/HjN4+zsbCb8clJUJMfN644Aigfk1W+SjZ4Dr+GLuY0BAPdybHEvxxYp15xw/i83bInZh+dfTMeBnWzmpMrtKb9b8HDLw6oZ2zTzbGwEmj+Vit4vnsUb7/dHn+CziPiwL66kVAUAXLpeDc2fSkWvF89i0cZ2ZoqcqOwsKtkrFAooFApzhyFJcpmArd0jrighK/7H1taCf/aSZJw4p0TEtD5a8ya/GYNrN93xzW/NobArAgCoH/o4q9UynnFi4aTcjG9RyZ4qRvioizj+Z3Wk37SHo1MROnZJRbM2dzBtxNPwqnUP7UPScCK2GrLu2KK6Zz76RyShIN8Gxw5WN3foRE90P88OV5K1T7XLy6+C7FwFriR7wMZGjRtprhj/xp9YseVZZOfYo+3TV9C6cTLe/zzETFGTSfCud+aRk5ODxMREzeOkpCTEx8fDw8MDderUMWNk0ubmUYAJs/+GR/V85OZUQdJFF0wb8TROHqkGjxp5aNLqDnr+3zU4uxYi87Yd/j5RFRPCn0HWHbsn75yoklOp5JiyKATD+x3D3NG74GBfhJR0V3y0tgOOnGa3IVkmmRDm+6myf/9+dOrUSWd+WFgYoqKinrh9dnY23Nzc8FLNoagiZ6Ih63S/la+5QyAqN0WFeTi0ewaysrLg6upaLscoyRVBXWahim3ZTxEuKsxD7G/TyzXW8mLWyr5jx44w428NIiKSEl4ul4iIiKwVB+gREZEkcDQ+ERGRtVML3XMqDd3eQjHZExGRNLDPnoiIiKwVK3siIpIEGYzsszdZJBWPyZ6IiKRBwlfQYzM+ERGRlWNlT0REksBT74iIiKwdR+MTERGRtWJlT0REkiATAjIjBtkZs625MdkTEZE0qP+djNneQrEZn4iIyMqxsiciIklgMz4REZG1k/BofCZ7IiKSBl5Bj4iIiKwVK3siIpIEXkGPiIjI2rEZn4iIiKwVK3siIpIEmbp4MmZ7S8VkT0RE0sBmfCIiIrJWrOyJiEgaeFEdIiIi6ybly+WyGZ+IiMjKsbInIiJpkPAAPSZ7IiKSBgHj7klvubmeyZ6IiKSBffZERERktZjsiYhIGgT+67cv01T2Q3/00UeQyWQYO3asZl5eXh7effddVKtWDc7Ozujbty/S0tKMfpqlYbInIiJpMCrRl31w37Fjx7By5Uo0b95ca/64ceOwfft2fP/99zhw4ABSUlLQp08fUzxTHUz2RERE5SQnJweDBg3C6tWrUbVqVc38rKwsrF27Fp999hlefPFFtG7dGuvWrcOhQ4dw+PBhk8fBZE9ERNKgNsFkoHfffRevvvoqgoODtebHxcWhsLBQa37Dhg1Rp04dxMbGGn6gJ+BofCIikgRTjcbPzs7Wmq9QKKBQKHTW//bbb3HixAkcO3ZMZ1lqairs7Ozg7u6uNd/T0xOpqalljvFRWNkTEREZwMfHB25ubppp/vz5Outcv34dY8aMwaZNm2Bvb2+GKLWxsiciImkw0RX0rl+/DldXV83s0qr6uLg4pKen4+mnn9bMU6lUiImJwRdffIHff/8dBQUFyMzM1Kru09LS4OXlVfYYH4HJnoiIpMFEyd7V1VUr2ZfmpZdewunTp7XmRUREoGHDhpg8eTJ8fHxga2uLPXv2oG/fvgCAhIQEXLt2DUFBQWWP8RGY7ImIiEzMxcUFTZs21Zrn5OSEatWqaeYPGTIE48ePh4eHB1xdXTFq1CgEBQXhueeeM3k8TPZERCQNlexGOIsWLYJcLkffvn2Rn5+PkJAQfPnllyY9RgkmeyIikgY1AJmR2xth//79Wo/t7e2xbNkyLFu2zLgd64HJnoiIJIE3wiEiIiKrxcqeiIikoZL12VckJnsiIpIGtQBkRiRsteUmezbjExERWTlW9kREJA1sxiciIrJ2RiZ7WG6yZzM+ERGRlWNlT0RE0sBmfCIiIiunFjCqKZ6j8YmIiKiyYmVPRETSINTFkzHbWygmeyIikgb22RMREVk59tkTERGRtWJlT0RE0sBmfCIiIisnYGSyN1kkFY7N+ERERFaOlT0REUkDm/GJiIisnFoNwIhz5dWWe549m/GJiIisHCt7IiKSBjbjExERWTkJJ3s24xMREVk5VvZERCQNEr5cLpM9ERFJghBqCCPuXGfMtubGZE9ERNIghHHVOfvsiYiIqLJiZU9ERNIgjOyzt+DKnsmeiIikQa0GZEb0u1twnz2b8YmIiKwcK3siIpIGNuMTERFZN6FWQxjRjG/Jp96xGZ+IiMjKsbInIiJpYDM+ERGRlVMLQCbNZM9mfCIiIivHyp6IiKRBCADGnGdvuZU9kz0REUmCUAsII5rxBZM9ERFRJSfUMK6y56l3REREVEmxsiciIklgMz4REZG1k3AzvkUn+5JfWUXqAjNHQlR+igrzzB0CUbkpKir+fFdE1VyEQqOuqVOEQtMFU8EsOtnfvXsXAHDg1gYzR0JUjnabOwCi8nf37l24ubmVy77t7Ozg5eWFg6m/Gr0vLy8v2NnZmSCqiiUTFtwJoVarkZKSAhcXF8hkMnOHIwnZ2dnw8fHB9evX4erqau5wiEyKn++KJ4TA3bt3oVQqIZeX35jxvLw8FBQY3wpsZ2cHe3t7E0RUsSy6spfL5ahdu7a5w5AkV1dX/jEkq8XPd8Uqr4r+Qfb29haZpE2Fp94RERFZOSZ7IiIiK8dkTwZRKBSYMWMGFAqFuUMhMjl+vslaWfQAPSIiInoyVvZERERWjsmeiIjIyjHZExERWTkmeyIiIivHZE96W7ZsGfz8/GBvb4/AwEAcPXrU3CERmURMTAy6d+8OpVIJmUyGbdu2mTskIpNisie9fPfddxg/fjxmzJiBEydOoEWLFggJCUF6erq5QyMyWm5uLlq0aIFly5aZOxSicsFT70gvgYGBeOaZZ/DFF18AKL4vgY+PD0aNGoUpU6aYOToi05HJZPjpp5/Qq1cvc4dCZDKs7OmJCgoKEBcXh+DgYM08uVyO4OBgxMbGmjEyIiLSB5M9PdGtW7egUqng6empNd/T0xOpqalmioqIiPTFZE9ERGTlmOzpiapXrw4bGxukpaVpzU9LS4OXl5eZoiIiIn0x2dMT2dnZoXXr1tizZ49mnlqtxp49exAUFGTGyIiISB9VzB0AWYbx48cjLCwMbdq0wbPPPovFixcjNzcXERER5g6NyGg5OTlITEzUPE5KSkJ8fDw8PDxQp04dM0ZGZBo89Y709sUXX2DhwoVITU1Fy5YtsWTJEgQGBpo7LCKj7d+/H506ddKZHxYWhqioqIoPiMjEmOyJiIisHPvsiYiIrByTPRERkZVjsiciIrJyTPZERERWjsmeiIjIyjHZExERWTkmeyIiIivHZE9kpPDwcK17n3fs2BFjx46t8Dj2798PmUyGzMzMR64jk8mwbds2vfcZGRmJli1bGhXXlStXIJPJEB8fb9R+iKjsmOzJKoWHh0Mmk0Emk8HOzg4BAQGYNWsWioqKyv3YP/74I2bPnq3XuvokaCIiY/Ha+GS1XnnlFaxbtw75+fn49ddf8e6778LW1hZTp07VWbegoAB2dnYmOa6Hh4dJ9kNEZCqs7MlqKRQKeHl5wdfXF++88w6Cg4Px888/A/iv6X3u3LlQKpVo0KABAOD69esYMGAA3N3d4eHhgZ49e+LKlSuafapUKowfPx7u7u6oVq0aJk2ahIevOP1wM35+fj4mT54MHx8fKBQKBAQEYO3atbhy5YrmeuxVq1aFTCZDeHg4gOK7Cs6fPx/+/v5wcHBAixYtsHXrVq3j/Prrr3jqqafg4OCATp06acWpr8mTJ+Opp56Co6Mj6tati2nTpqGwsFBnvZUrV8LHxweOjo4YMGAAsrKytJavWbMGjRo1gr29PRo2bIgvv/zS4FiIqPww2ZNkODg4oKCgQPN4z549SEhIQHR0NHbs2IHCwkKEhITAxcUFf/zxB/788084OzvjlVde0Wz36aefIioqCl999RUOHjyIjIwM/PTTT4897htvvIFvvvkGS5Yswblz57By5Uo4OzvDx8cHP/zwAwAgISEBN2/exOeffw4AmD9/PjZs2IAVK1bgzJkzGDduHAYPHowDBw4AKP5R0qdPH3Tv3h3x8fEYOnQopkyZYvBr4uLigqioKJw9exaff/45Vq9ejUWLFmmtk5iYiC1btmD79u3YuXMnTp48iREjRmiWb9q0CdOnT8fcuXNx7tw5zJs3D9OmTcP69esNjoeIyokgskJhYWGiZ8+eQggh1Gq1iI6OFgqFQrz33nua5Z6eniI/P1+zzcaNG0WDBg2EWq3WzMvPzxcODg7i999/F0II4e3tLRYsWKBZXlhYKGrXrq05lhBCdOjQQYwZM0YIIURCQoIAIKKjo0uNc9++fQKAuHPnjmZeXl6ecHR0FIcOHdJad8iQIWLgwIFCCCGmTp0qGjdurLV88uTJOvt6GADx008/PXL5woULRevWrTWPZ8yYIWxsbMSNGzc083777Tchl8vFzZs3hRBC1KtXT2zevFlrP7NnzxZBQUFCCCGSkpIEAHHy5MlHHpeIyhf77Mlq7dixA87OzigsLIRarcb//d//ITIyUrO8WbNmWv30p06dQmJiIlxcXLT2k5eXh0uXLiErKws3b97Uuq1vlSpV0KZNG52m/BLx8fGwsbFBhw4d9I47MTER9+7dQ+fOnbXmFxQUoFWrVgCAc+fO6dxeOCgoSO9jlPjuu++wZMkSXLp0CTk5OSgqKoKrq6vWOnXq1EGtWrW0jqNWq5GQkAAXFxdcunQJQ4YMwbBhwzTrFBUVwc3NzeB4iKh8MNmT1erUqROWL18OOzs7KJVKVKmi/XF3cnLSepyTk4PWrVtj06ZNOvuqUaNGmWJwcHAweJucnBwAwC+//KKVZIHicQimEhsbi0GDBmHmzJkICQmBm5sbvv32W3z66acGx7p69WqdHx82NjYmi5WIjMNkT1bLyckJAQEBeq//9NNP47vvvkPNmjV1qtsS3t7eOHLkCNq3bw+guIKNi4vD008/Xer6zZo1g1qtxoEDBxAcHKyzvKRlQaVSaeY1btwYCoUC165de2SLQKNGjTSDDUscPnz4yU/yAYcOHYKvry8++OADzbyrV6/qrHft2jWkpKRAqVRqjiOXy9GgQQN4enpCqVTi8uXLGDRokEHHJ6KKwwF6RP8aNGgQqlevjp49e+KPP/5AUlIS9u/fj9GjR+PGjRsAgDFjxuCjjz7Ctm3bcP78eYwYMeKx58j7+fkhLCwMb775JrZt26bZ55YtWwAAvr6+kMlk2LFjB/755x/k5OTAxcUF7733HsaNG4f169fj0qVLOHHiBJYuXaoZ9Pb222/j4sWLmDhxIhISErB582ZERUUZ9Hzr16+Pa9eu4dtvv8WlS5ewZMmSUgcb2tvbIywsDKdOncIff/yB0aNHY8CAAfDy8gIAzJw5E/Pnz8eSJUtw4cIFnD59GuvWrcNnn31mUDxEVH6Y7In+5ejoiJiYGNSpUwd9+vRBo0aNMGTIEOTl5Wkq/QkTJuD1119HWFgYgoKC4OLigt69ez92v8uXL0e/fv0wYsQINGzYEMOGDUNubi4AoFatWpg5cyamTJkCT09PjBw5EgAwe/ZsTJs2DfPnz0ejRo3wyiuv4JdffoG/vz+A4n70H374Adu2bUOLFi2wYsUKzJs3z6Dn26NHD4wbNw4jR45Ey5YtcejQIUybNk1nvYCAAPTp0wddu3bFyy+/jObNm2udWjd06FCsWbMG69atQ7NmzdChQwdERUVpYiUi85OJR40sIiIiIqvAyp6IiMjKMdkTERFZOSZ7IiIiK8dkT0REZOWY7ImIiKwckz0REZGVY7InIiKyckz2REREVo7JnoiIyMox2RMREVk5JnsiIiIrx2RPRERk5f4fmqzMQBMEiUIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Stacking**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.ensemble  import AdaBoostClassifier\r\n",
    "from xgboost import XGBClassifier\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "from sklearn.ensemble  import GradientBoostingClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.svm import SVC \r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\r\n",
    "from sklearn.linear_model import Perceptron\r\n",
    "from mlxtend.classifier import StackingClassifier\r\n",
    "from sklearn.ensemble import VotingClassifier\r\n",
    "%matplotlib inline\r\n",
    "from sklearn import model_selection\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Feature Scaling**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "min_train = X_train.min()\r\n",
    "range_train = (X_train - min_train).max()\r\n",
    "X_train_scaled = (X_train - min_train)/range_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "min_test = X_test.min()\r\n",
    "range_test = (X_test - min_test).max()\r\n",
    "X_test_scaled = (X_test - min_test)/range_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "logi = LogisticRegression()\r\n",
    "logi.fit(X_train_scaled, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "y_predict = logi.predict(X_test_scaled)\r\n",
    "from sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "roc=roc_auc_score(y_test, y_predict)\r\n",
    "\r\n",
    "acc = accuracy_score(y_test, y_predict)\r\n",
    "prec = precision_score(y_test, y_predict)\r\n",
    "rec = recall_score(y_test, y_predict)\r\n",
    "f1 = f1_score(y_test, y_predict)\r\n",
    "\r\n",
    "results = pd.DataFrame([['Logistic Regression', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.74026</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Logistic Regression   0.74026   0.705882  0.444444  0.545455  0.672222"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "from xgboost import XGBClassifier\r\n",
    "xgb_classifier = XGBClassifier()\r\n",
    "xgb_classifier.fit(X_train_scaled, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[16:01:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "y_predict = xgb_classifier.predict(X_test_scaled)\r\n",
    "roc=roc_auc_score(y_test, y_predict)\r\n",
    "acc = accuracy_score(y_test, y_predict)\r\n",
    "prec = precision_score(y_test, y_predict)\r\n",
    "rec = recall_score(y_test, y_predict)\r\n",
    "f1 = f1_score(y_test, y_predict)\r\n",
    "\r\n",
    "model_results = pd.DataFrame([['XGBOOST', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results = results.append(model_results, ignore_index = True)\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.74026</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.74026</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.669383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Logistic Regression   0.74026   0.705882  0.444444  0.545455  0.672222\n",
       "1              XGBOOST   0.74026   0.714286  0.432099  0.538462  0.669383"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "random_forest = RandomForestClassifier()\r\n",
    "random_forest.fit(X_train_scaled, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "y_predict = random_forest.predict(X_test_scaled)\r\n",
    "roc=roc_auc_score(y_test, y_predict)\r\n",
    "acc = accuracy_score(y_test, y_predict)\r\n",
    "prec = precision_score(y_test, y_predict)\r\n",
    "rec = recall_score(y_test, y_predict)\r\n",
    "f1 = f1_score(y_test, y_predict)\r\n",
    "\r\n",
    "model_results = pd.DataFrame([['Random Forest', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results = results.append(model_results, ignore_index = True)\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.669383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Logistic Regression  0.740260   0.705882  0.444444  0.545455  0.672222\n",
       "1              XGBOOST  0.740260   0.714286  0.432099  0.538462  0.669383\n",
       "2        Random Forest  0.727273   0.673077  0.432099  0.526316  0.659383"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "sgd = SGDClassifier(max_iter=1000)\r\n",
    "\r\n",
    "sgd.fit(X_train_scaled, y_train)\r\n",
    "y_predict = sgd.predict(X_test_scaled)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "roc=roc_auc_score(y_test, y_predict)\r\n",
    "acc = accuracy_score(y_test, y_predict)\r\n",
    "prec = precision_score(y_test, y_predict)\r\n",
    "rec = recall_score(y_test, y_predict)\r\n",
    "f1 = f1_score(y_test, y_predict)\r\n",
    "\r\n",
    "model_results = pd.DataFrame([['SGD', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results = results.append(model_results, ignore_index = True)\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.669383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.667778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Logistic Regression  0.740260   0.705882  0.444444  0.545455  0.672222\n",
       "1              XGBOOST  0.740260   0.714286  0.432099  0.538462  0.669383\n",
       "2        Random Forest  0.727273   0.673077  0.432099  0.526316  0.659383\n",
       "3                  SGD  0.601732   0.464516  0.888889  0.610169  0.667778"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "adaboost =AdaBoostClassifier()\r\n",
    "adaboost.fit(X_train_scaled, y_train)\r\n",
    "y_predict = adaboost.predict(X_test_scaled)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "roc=roc_auc_score(y_test, y_predict)\r\n",
    "acc = accuracy_score(y_test, y_predict)\r\n",
    "prec = precision_score(y_test, y_predict)\r\n",
    "rec = recall_score(y_test, y_predict)\r\n",
    "f1 = f1_score(y_test, y_predict)\r\n",
    "\r\n",
    "model_results = pd.DataFrame([['Adaboost', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results = results.append(model_results, ignore_index = True)\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.669383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.667778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.599136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Logistic Regression  0.740260   0.705882  0.444444  0.545455  0.672222\n",
       "1              XGBOOST  0.740260   0.714286  0.432099  0.538462  0.669383\n",
       "2        Random Forest  0.727273   0.673077  0.432099  0.526316  0.659383\n",
       "3                  SGD  0.601732   0.464516  0.888889  0.610169  0.667778\n",
       "4             Adaboost  0.696970   0.666667  0.271605  0.385965  0.599136"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "gboost =GradientBoostingClassifier()\r\n",
    "gboost.fit(X_train_scaled, y_train)\r\n",
    "y_predict = gboost.predict(X_test_scaled)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "roc=roc_auc_score(y_test, y_predict)\r\n",
    "acc = accuracy_score(y_test, y_predict)\r\n",
    "prec = precision_score(y_test, y_predict)\r\n",
    "rec = recall_score(y_test, y_predict)\r\n",
    "f1 = f1_score(y_test, y_predict)\r\n",
    "\r\n",
    "model_results = pd.DataFrame([['Gboost', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results = results.append(model_results, ignore_index = True)\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.669383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.667778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.599136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gboost</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.637531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Logistic Regression  0.740260   0.705882  0.444444  0.545455  0.672222\n",
       "1              XGBOOST  0.740260   0.714286  0.432099  0.538462  0.669383\n",
       "2        Random Forest  0.727273   0.673077  0.432099  0.526316  0.659383\n",
       "3                  SGD  0.601732   0.464516  0.888889  0.610169  0.667778\n",
       "4             Adaboost  0.696970   0.666667  0.271605  0.385965  0.599136\n",
       "5               Gboost  0.709957   0.640000  0.395062  0.488550  0.637531"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 7)\r\n",
    "knn.fit(X_train_scaled, y_train)\r\n",
    "y_predict = knn.predict(X_test_scaled)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "roc=roc_auc_score(y_test, y_predict)\r\n",
    "acc = accuracy_score(y_test, y_predict)\r\n",
    "prec = precision_score(y_test, y_predict)\r\n",
    "rec = recall_score(y_test, y_predict)\r\n",
    "f1 = f1_score(y_test, y_predict)\r\n",
    "\r\n",
    "model_results = pd.DataFrame([['KNN7', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results = results.append(model_results, ignore_index = True)\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.669383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.667778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.599136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gboost</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.637531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN7</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.666914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Logistic Regression  0.740260   0.705882  0.444444  0.545455  0.672222\n",
       "1              XGBOOST  0.740260   0.714286  0.432099  0.538462  0.669383\n",
       "2        Random Forest  0.727273   0.673077  0.432099  0.526316  0.659383\n",
       "3                  SGD  0.601732   0.464516  0.888889  0.610169  0.667778\n",
       "4             Adaboost  0.696970   0.666667  0.271605  0.385965  0.599136\n",
       "5               Gboost  0.709957   0.640000  0.395062  0.488550  0.637531\n",
       "6                 KNN7  0.718615   0.625000  0.493827  0.551724  0.666914"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "from sklearn.svm import SVC \r\n",
    "\r\n",
    "\r\n",
    "svc_model = SVC(kernel='linear')\r\n",
    "svc_model.fit(X_train, y_train)\r\n",
    "y_predict = svc_model.predict(X_test_scaled)\r\n",
    "roc=roc_auc_score(y_test, y_predict)\r\n",
    "acc = accuracy_score(y_test, y_predict)\r\n",
    "prec = precision_score(y_test, y_predict)\r\n",
    "rec = recall_score(y_test, y_predict)\r\n",
    "f1 = f1_score(y_test, y_predict)\r\n",
    "\r\n",
    "model_results = pd.DataFrame([['SVC Linear', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results = results.append(model_results, ignore_index = True)\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.669383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.667778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.599136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gboost</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.637531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN7</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.666914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC Linear</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Logistic Regression  0.740260   0.705882  0.444444  0.545455  0.672222\n",
       "1              XGBOOST  0.740260   0.714286  0.432099  0.538462  0.669383\n",
       "2        Random Forest  0.727273   0.673077  0.432099  0.526316  0.659383\n",
       "3                  SGD  0.601732   0.464516  0.888889  0.610169  0.667778\n",
       "4             Adaboost  0.696970   0.666667  0.271605  0.385965  0.599136\n",
       "5               Gboost  0.709957   0.640000  0.395062  0.488550  0.637531\n",
       "6                 KNN7  0.718615   0.625000  0.493827  0.551724  0.666914\n",
       "7           SVC Linear  0.649351   0.000000  0.000000  0.000000  0.500000"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Voting Classifier**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "clf1=LogisticRegression()\r\n",
    "clf2 = RandomForestClassifier()\r\n",
    "clf3=AdaBoostClassifier()\r\n",
    "clf4=XGBClassifier()\r\n",
    "clf5=SGDClassifier(max_iter=1000,loss='log')\r\n",
    "clf6=KNeighborsClassifier(n_neighbors = 7)\r\n",
    "clf7=GradientBoostingClassifier()\r\n",
    "\r\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('ada', clf3),('xgb',clf4),('sgd',clf5),('knn',clf6),('gboost',clf7)], voting='soft', weights=[1,1,2,2,1,3,2])\r\n",
    "eclf1.fit(X_train_scaled,y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[16:04:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()),\n",
       "                             ('ada', AdaBoostClassifier()),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, m...\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None)),\n",
       "                             ('sgd', SGDClassifier(loss='log')),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=7)),\n",
       "                             ('gboost', GradientBoostingClassifier())],\n",
       "                 voting='soft', weights=[1, 1, 2, 2, 1, 3, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "eclf_predictions = eclf1.predict(X_test_scaled)\r\n",
    "acc = accuracy_score(y_test, eclf_predictions)\r\n",
    "prec = precision_score(y_test, eclf_predictions)\r\n",
    "rec = recall_score(y_test, eclf_predictions)\r\n",
    "f1 = f1_score(y_test, eclf_predictions)\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "roc=roc_auc_score(y_test, eclf_predictions)\r\n",
    "model_results = pd.DataFrame([['Voting Classifier ', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results = results.append(model_results, ignore_index = True)\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.669383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.667778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.599136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gboost</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.637531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN7</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.666914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC Linear</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Logistic Regression  0.740260   0.705882  0.444444  0.545455  0.672222\n",
       "1              XGBOOST  0.740260   0.714286  0.432099  0.538462  0.669383\n",
       "2        Random Forest  0.727273   0.673077  0.432099  0.526316  0.659383\n",
       "3                  SGD  0.601732   0.464516  0.888889  0.610169  0.667778\n",
       "4             Adaboost  0.696970   0.666667  0.271605  0.385965  0.599136\n",
       "5               Gboost  0.709957   0.640000  0.395062  0.488550  0.637531\n",
       "6                 KNN7  0.718615   0.625000  0.493827  0.551724  0.666914\n",
       "7           SVC Linear  0.649351   0.000000  0.000000  0.000000  0.500000\n",
       "8   Voting Classifier   0.727273   0.673077  0.432099  0.526316  0.659383"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Stacking**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "clf1=LogisticRegression()\r\n",
    "clf2 = RandomForestClassifier()\r\n",
    "clf3=AdaBoostClassifier()\r\n",
    "clf4=XGBClassifier()\r\n",
    "clf5=SGDClassifier(max_iter=1000,loss='log')\r\n",
    "clf6=GradientBoostingClassifier()\r\n",
    "knn=KNeighborsClassifier(n_neighbors = 7)\r\n",
    "\r\n",
    "\r\n",
    "sclf = StackingClassifier(classifiers=[clf1,clf2, clf3, clf4,clf5,clf6], \r\n",
    "                        meta_classifier=knn)\r\n",
    "\r\n",
    "print('10-fold cross validation:\\n')\r\n",
    "\r\n",
    "for clf, label in zip([clf1,clf2, clf3, clf4,clf5,clf6, sclf], \r\n",
    "                    ['Logistic Regression'\r\n",
    "                    'Random Forest', \r\n",
    "                    'Adaboost',\r\n",
    "                        'XGB','SGD','Gradient',\r\n",
    "                    'StackingClassifier']):\r\n",
    "\r\n",
    "    scores = model_selection.cross_val_score(clf, X_test_scaled, y_test,\r\n",
    "                                            cv=10, scoring='accuracy')\r\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \r\n",
    "        % (scores.mean(), scores.std(), label))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "Accuracy: 0.70 (+/- 0.06) [Logistic RegressionRandom Forest]\n",
      "Accuracy: 0.71 (+/- 0.08) [Adaboost]\n",
      "Accuracy: 0.70 (+/- 0.10) [XGB]\n",
      "[17:11:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:11:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17:11:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:11:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.69 (+/- 0.07) [SGD]\n",
      "Accuracy: 0.67 (+/- 0.13) [Gradient]\n",
      "Accuracy: 0.74 (+/- 0.07) [StackingClassifier]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "import time\r\n",
    "parameters = {\r\n",
    "        'min_child_weight': [1, 5,7, 10],\r\n",
    "        'max_depth': [2,3, 5,7,10,12],\r\n",
    "        'n_estimators':[10,50,100,200]\r\n",
    "        }\r\n",
    "\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "grid_search = GridSearchCV(estimator = xgb_classifier, # Make sure classifier points to the RF model\r\n",
    "                        param_grid = parameters,\r\n",
    "                        scoring = \"accuracy\",\r\n",
    "                        cv = 5,\r\n",
    "                        n_jobs = -1)\r\n",
    "\r\n",
    "t0 = time.time()\r\n",
    "grid_search.fit(X_train_scaled, y_train)\r\n",
    "t1 = time.time()\r\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17:12:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Took 27.57 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "grid_search.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'min_child_weight': 10, 'n_estimators': 10}"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "grid_predictions = grid_search.predict(X_test_scaled)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\r\n",
    "cm = confusion_matrix(y_test, grid_predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "sns.heatmap(cm, annot=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 64
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGdCAYAAACGtNCDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAl0ElEQVR4nO3de1hVdb7H8c/GCxLKJjS5TJJUdjRz1NAIzUZHim4mhjl2aKJyciqklEqjCe2+y5r04I3JKa1TNlMzo6VnsuNgSiWhYlqaoY7mtY0SIYGyRfc+f3jaspZUYgvWrv1+Pc96HvdvXfaXnsf88v3+fr/l8Pl8PgEAAPy/ELsDAAAAgYXkAAAAGJAcAAAAA5IDAABgQHIAAAAMSA4AAIAByQEAADAgOQAAAAYkBwAAwKC13QF8q75iu90hAAEnLG6Q3SEAAenokb3N+nwr/01q0+lcy57VUgImOQAAIGB4j9kdga1oKwAAAAMqBwAAmPm8dkdgK5IDAADMvCQHAACgAV+QVw6YcwAAAAyoHAAAYEZbAQAAGNBWAAAAOIHKAQAAZkG+CRLJAQAAZrQVAAAATqByAACAGasVAABAQ2yCBAAA0ACVAwAAzGgrAAAAgyBvK5AcAABgFuT7HDDnAAAAGFA5AADAjLYCAAAwCPIJibQVAACAAZUDAADMaCsAAAAD2goAAAAnUDkAAMDE5wvufQ5IDgAAMAvyOQe0FQAAgAGVAwAAzIJ8QiLJAQAAZkHeViA5AADAjBcvAQAAnEDlAAAAM9oKAADAIMgnJNJWAAAABlQOAAAwo60AAAAMaCsAAACcQHIAAICZ12vd0QRFRUUaNmyY4uLi5HA4tGjRIv+5+vp6TZo0Sb169VJ4eLji4uJ0yy23aN++fYZnVFZWKiMjQxEREYqMjNSYMWNUU1PTpDhIDgAAMPH5jll2NEVtba169+6tWbNmnXTu0KFDWrdunfLy8rRu3Tr94x//UFlZma6//nrDdRkZGdq0aZOWLVumJUuWqKioSGPHjm1SHA6fz+dr0h3NpL5iu90hAAEnLG6Q3SEAAenokb3N+vzDRfMte1bY5bee1n0Oh0MLFy5UWlrad16zZs0aXXLJJdq5c6fi4+O1efNmXXjhhVqzZo369esnSVq6dKmuueYa7dmzR3Fxcaf03VQOAAAws6mt0FQHDx6Uw+FQZGSkJKm4uFiRkZH+xECSUlJSFBISopKSklN+LqsVAAAws3Apo8fjkcfjMYyFhoYqNDT0Rz23rq5OkyZN0k033aSIiAhJktvtVufOnQ3XtW7dWlFRUXK73af8bCoHAACYWVg5cLlccjqdhsPlcv2o8Orr6zVq1Cj5fD7NmTPHoh/6BCoHAAA0o9zcXOXk5BjGfkzV4NvEYOfOnVq+fLm/aiBJMTEx2r9/v+H6o0ePqrKyUjExMaf8HSQHAACYWdhWsKKF8K1vE4OtW7fqvffeU8eOHQ3nk5OTVVVVpdLSUiUmJkqSli9fLq/Xq6SkpFP+HpIDAADMbNohsaamRtu2bfN/3rFjh9avX6+oqCjFxsZq5MiRWrdunZYsWaJjx4755xFERUWpbdu26tGjh6666irdcccdKigoUH19vcaNG6fRo0ef8koFiaWMQEBjKSPQuGZfyvi/sy17VtiVd5/ytStWrNCQIUNOGs/MzNQjjzyihISERu977733NHjwYEnHN0EaN26cFi9erJCQEKWnpys/P1/t27c/5TioHAAAYGbTi5cGDx6s7/ud/VR+n4+KitKCBQt+VBwkBwAAmPHiJQAAgBOoHAAAYBbklQOSAwAAzGyacxAoaCsAAAADKgcAAJjRVgAAAAZB3lYgOQAAwCzIKwfMOQAAAAZUDgAAMKOtAAAADGgrAAAAnEDlAAAAsyCvHJAcAABgdgpvP/w5o60AAAAMqBwAAGBGWwEAABgEeXJAWwEAABhQOQAAwIxNkAAAgEGQtxVIDgAAMGMpIwAAwAlUDgAAMKOtAAAADII8OaCtAAAADKgcAABgxlJGAADQkM/LagUAAAA/KgcAAJgF+YREkgMAAMyCfM4BbQUAAGBA5QAAALMgn5BIcgAAgBlzDgAAgEGQJwfMOQAAAAZUDgAAMOOVzQh0a9d/qqyJUzTk+gxdNPBqFRat+t7r123YqJvvvE8Drx6lxCHDNeymO/TKXxY2e5zvLn9fw266QxcPuV4jfnuXilat9p+rP3pUz89+USN+e5f6D03TkOszlPv4c9p/4Ktmjws4VYMuS9KihfO164tSHT2yV9dfn3rSNd27n6+F/5inrw5s1sGvt6p41f+oS5c4G6JFs/J6rTt+gkgOfgIOH67Tf5x/rv5w392ndH1YWDv9Z/owvTzrWb294AWNvfUmzZj7st5865+nHcPqdZ/oyvTM7zz/8aefaeIjT2vEdal6c95M/XpQsu7JfVxbt38hSaqr8+izsn/r97fepDdemqnpTz2sL3bt0bhJj552TIDVwsPP0CeffKbse//Q6Plzzz1HK99bpLKybRp6xUj1TUzRk09NV12dp4UjBZoXbYWfgEHJ/TUouf8pX9/jgvPV44Lz/Z9/ERutf634UKUbNunG4ddIkrxer1589U397e13VPHV1zon/he689abdOWQQacV46tvvKWBSf10e8ZISVL22FtUvGadFvxtsaZMzFaH9uH68389ZbjnoZy7dNPvxutL937FxnQ+re8FrLT03fe09N33vvP8449N0jtLl+vB3Cf9Y9u372yJ0NDSgnwpY5MrBxUVFZo6dapGjBih5ORkJScna8SIEXr22Wd14MCB5ogRP9LmLdu0fuNm9evTyz8297//qreXFmryA9la9GqBbhk1Qg8+9qzWfPzJaX3Hhk2bldyvj2FsQFKiNmza/J331NQcksPhUIcO4af1nUBLcjgcuubqodq6dbv+ueQ17duzQas+WNxo6wE/Az6vdcdPUJOSgzVr1uiCCy5Qfn6+nE6nLr/8cl1++eVyOp3Kz89X9+7dtXbt2uaKFU00NO1m9R08TL8Zc69uuuE6jbz+KknSkSNH9OdX/qrHH5qggUmJ6vKLWKVde4Wuu/LXevOtd07ruyq++lodo840jHWKOlMVX33d6PUezxFNm/OSrkn5ldqHkxwg8HXu3EkdOrTXxAey9O7/rtDV1/6nFr21VH9748+6fNCldocHWKpJbYXs7GzdeOONKigokMPhMJzz+Xy68847lZ2dreLi4u99jsfjkcdj7NGFeDwKDQ1tSjj4AS/Pfk6HDh/WJ5s+17Q58xR/dpyuuWKwdu35UofrPLpj/EOG6+vrj6rHBef5P/dPGeH/s/eYV0fq6w1j1135a02ZmN3kuOqPHtV9eU/J5/Mp74Fxp/GTAS0vJOT471JvL35X/5U/V5K0YcMmJSf309ixv1XR+x/ZGR6sFuRthSYlBxs2bND8+fNPSgyk4yW3CRMmqG/fvj/4HJfLpUcfNU5Ee/iBezR54r1NCQc/4Oy4GEnSBecl6KvKKs1+8VVdc8VgHTp8WJI0+9lHFX1WJ8M9bdq08f/57/Nn+f98PMF4SfNmTvWPhYef4f9zp45n6qtKY5WgovJrdeporCZ8mxjsK9+vl/KfpmqAn4yKikrV19dr8+athvHPP9+qgQMusSkqNBffT3SVgVWalBzExMRo9erV6t69e6PnV69erejo6B98Tm5urnJycgxjId/sbUooaCKv9/hv/pJ0Xtd4tW3bRl+WH1D/vr/8znvizz6xPMu9v0KtWrUyjDXUu2cPfVS6Xr/9zYnKQvGaj9W7Zw//528Tg1279+mlGU8r0hnxY38soMXU19dr7doNuqBBdU2SunU7Vzt37bEpKqB5NCk5uP/++zV27FiVlpZq6NCh/kSgvLxchYWFmjt3rp577rkffE5oaOhJLYT6IxVNCSWoHDp0WLv27PN/3ruvXJ9v+becER0UG9NZ0+bM0/6Kr+TKu1+S9PrfFys2+iwlnNNFkrR2/UbNf/3vyrhxuKTjv/HfelO6pua/IJ/Xq76/7Kma2kP6+JNNah9+hoZfc0WTY7x51HDdljVR81//uy4fcIne+ddKbfp8qx6ZdI+k44lBzh+e1GdbtmnW1Efl9XpV8VWlJMkZ0cFQsQDsEh5+hs4/P8H/OaFrvHr37qnKyq+1e/c+Pff8HL3+2hy9//5HWrFylVKvHKzrrr1CQ1NG2hg1mgVthVOXlZWlTp06adq0aZo9e7aOHTsmSWrVqpUSExM1f/58jRo1qlkCDWYbP9+q27Mn+T9PnfGCJGn41Sl68uH7VPFVpb4s3+8/7/V6Nb1gvvZ+6VarVq3U5RexmnD37Rr1/8sYJSn7jlt0ZqRTf/7vN7R7n1sR7cPV4z/O1x23/Oa0Yuzb60I988gkzXjhZf3Xn+brnLN/oXxXnrqd21WStP/AV3rvg+M92ZG3ZhnufWnGM7rk4u+uYAAtpV9ibxX+62/+z3987hFJ0suvvKExv5ugt95aqruzHtSkidmaPu0xlW3Zrht/c4c+XLXGpojRbH6iqwys4vD5Tm+PyPr6elVUHP9tv1OnTj/6N7/6iu0/6n7g5ygs7vT2nQB+7o4ead5WdO1jGZY9K3zya5Y9q6Wc9iZIbdq0UWxsrJWxAACAAMAOiQAAmLFaAQAAGAT5hERevAQAAAyoHAAAYBbkqxWoHAAAYOb1WXc0QVFRkYYNG6a4uDg5HA4tWrTIcN7n82ny5MmKjY1VWFiYUlJStHWrcdfOyspKZWRkKCIiQpGRkRozZoxqamqaFAfJAQAAAaK2tla9e/fWrFmzGj0/depU5efnq6CgQCUlJQoPD1dqaqrq6ur812RkZGjTpk1atmyZlixZoqKiIo0dO7ZJcZz2PgdWY58D4GTscwA0rrn3OajJTbfsWe1dfz+t+xwOhxYuXKi0tDRJx6sGcXFxuu+++3T//cd3xD148KCio6M1f/58jR49Wps3b9aFF16oNWvWqF+/fpKkpUuX6pprrtGePXsUF9f4FvhmVA4AADCzsK3g8XhUXV1tOMxvJj4VO3bskNvtVkpKin/M6XQqKSnJ/zbk4uJiRUZG+hMDSUpJSVFISIhKSkpO+btIDgAAaEYul0tOp9NwuFyuJj/H7XZL0kkvOIyOjvafc7vd6ty5s+F869atFRUV5b/mVLBaAQAAMwv3OWjsTcTmlw8GGpIDAADMLFzK2NibiE9HTEyMpONvQm74+oLy8nL16dPHf83+/fsN9x09elSVlZX++08FbQUAAMxsWsr4fRISEhQTE6PCwkL/WHV1tUpKSpScnCxJSk5OVlVVlUpLS/3XLF++XF6vV0lJSaf8XVQOAAAIEDU1Ndq2bZv/844dO7R+/XpFRUUpPj5e48eP1xNPPKFu3bopISFBeXl5iouL869o6NGjh6666irdcccdKigoUH19vcaNG6fRo0ef8koFieQAAICT+Gx6t8LatWs1ZMgQ/+dv5ypkZmZq/vz5mjhxomprazV27FhVVVXpsssu09KlS9WuXTv/Pa+99prGjRunoUOHKiQkROnp6crPz29SHOxzAAQw9jkAGtfc+xx8c891lj2rQ/4Sy57VUphzAAAADGgrAABg5g3uFy+RHAAAYGbTnINAQVsBAAAYUDkAAMAsyCsHJAcAAJgEyEI+29BWAAAABlQOAAAwo60AAAAMSA4AAEBDdm2fHCiYcwAAAAyoHAAAYBbklQOSAwAAzIJ792TaCgAAwIjKAQAAJsE+IZHkAAAAsyBPDmgrAAAAAyoHAACYBfmERJIDAABMgn3OAW0FAABgQOUAAAAz2goAAKChYG8rkBwAAGAW5JUD5hwAAAADKgcAAJj4grxyQHIAAIBZkCcHtBUAAIABlQMAAExoKwAAAKMgTw5oKwAAAAMqBwAAmNBWAAAABiQHAADAINiTA+YcAAAAAyoHAACY+Rx2R2ArkgMAAExoKwAAADRA5QAAABOfl7YCAABogLYCAABAA1QOAAAw8bFaAQAANERbAQAAoAEqBwAAmLBaAQAAGPh8dkdgL5IDAABMgr1ywJwDAABgQOUAAACTYK8ckBwAAGAS7HMOaCsAAAADKgcAAJjQVgAAAAbBvn0ybQUAAALEsWPHlJeXp4SEBIWFhem8887T448/Ll+DSRA+n0+TJ09WbGyswsLClJKSoq1bt1oaB8kBAAAmPq91R1M888wzmjNnjmbOnKnNmzfrmWee0dSpUzVjxgz/NVOnTlV+fr4KCgpUUlKi8PBwpaamqq6uzrKfn7YCAAAmXpvaCqtWrdLw4cN17bXXSpK6du2q119/XatXr5Z0vGowffp0Pfzwwxo+fLgk6ZVXXlF0dLQWLVqk0aNHWxIHlQMAAJqRx+NRdXW14fB4PI1eO2DAABUWFmrLli2SpA0bNuiDDz7Q1VdfLUnasWOH3G63UlJS/Pc4nU4lJSWpuLjYsphJDgAAMPH5HJYdLpdLTqfTcLhcrka/98EHH9To0aPVvXt3tWnTRn379tX48eOVkZEhSXK73ZKk6Ohow33R0dH+c1agrQAAgImVSxlzc3OVk5NjGAsNDW302jfeeEOvvfaaFixYoJ49e2r9+vUaP3684uLilJmZaVlMP4TkAAAAEyt3SAwNDf3OZMDsgQce8FcPJKlXr17auXOnXC6XMjMzFRMTI0kqLy9XbGys/77y8nL16dPHsphpKwAAECAOHTqkkBDjP82tWrWS13t82UNCQoJiYmJUWFjoP19dXa2SkhIlJydbFgeVAwAATOzaIXHYsGF68sknFR8fr549e+rjjz/W888/r9tvv12S5HA4NH78eD3xxBPq1q2bEhISlJeXp7i4OKWlpVkWB8kBAAAmdi1lnDFjhvLy8nT33Xdr//79iouL0+9//3tNnjzZf83EiRNVW1ursWPHqqqqSpdddpmWLl2qdu3aWRaHw+cLjHdP1VdstzsEIOCExQ2yOwQgIB09srdZn7/x3Osse9ZF25dY9qyWQuUAAACTYH+3AskBAAAmgVFTtw+rFQAAgAGVAwAATOyakBgoSA4AADAJ9jkHtBUAAIABlQMAAEyCfUIiyQEAACbMOQgQE/s9ZHcIQMDpFdXV7hCAoMScAwAAgAYCpnIAAECgoK0AAAAMgnw+Im0FAABgROUAAAAT2goAAMCA1QoAAAANUDkAAMDEa3cANiM5AADAxCfaCgAAAH5UDgAAMPEG+UYHJAcAAJh4g7ytQHIAAIAJcw4AAAAaoHIAAIAJSxkBAIABbQUAAIAGqBwAAGBCWwEAABgEe3JAWwEAABhQOQAAwCTYJySSHAAAYOIN7tyAtgIAADCicgAAgAnvVgAAAAZB/lJGkgMAAMxYyggAANAAlQMAAEy8DuYcAACABoJ9zgFtBQAAYEDlAAAAk2CfkEhyAACACTskAgAANEDlAAAAE3ZIBAAABqxWAAAAaIDKAQAAJsE+IZHkAAAAE5YyAgAAA+YcAAAANEDlAAAAE+YcAAAAg2Cfc0BbAQCAALJ3717dfPPN6tixo8LCwtSrVy+tXbvWf97n82ny5MmKjY1VWFiYUlJStHXrVktjIDkAAMDEa+HRFF9//bUGDhyoNm3a6J133tFnn32mP/7xjzrzzDP910ydOlX5+fkqKChQSUmJwsPDlZqaqrq6uh/zIxvQVgAAwMRn05yDZ555Rl26dNG8efP8YwkJCf4/+3w+TZ8+XQ8//LCGDx8uSXrllVcUHR2tRYsWafTo0ZbEQeUAAIBm5PF4VF1dbTg8Hk+j17799tvq16+fbrzxRnXu3Fl9+/bV3Llz/ed37Nght9utlJQU/5jT6VRSUpKKi4sti5nkAAAAEyvbCi6XS06n03C4XK5Gv3f79u2aM2eOunXrpnfffVd33XWX7rnnHr388suSJLfbLUmKjo423BcdHe0/ZwXaCgAAmFi5WiE3N1c5OTmGsdDQ0Ma/1+tVv3799NRTT0mS+vbtq40bN6qgoECZmZkWRvX9qBwAANCMQkNDFRERYTi+KzmIjY3VhRdeaBjr0aOHdu3aJUmKiYmRJJWXlxuuKS8v95+zAskBAAAmPguPphg4cKDKysoMY1u2bNE555wj6fjkxJiYGBUWFvrPV1dXq6SkRMnJyU38tu9GWwEAABO7dkicMGGCBgwYoKeeekqjRo3S6tWr9cILL+iFF16QJDkcDo0fP15PPPGEunXrpoSEBOXl5SkuLk5paWmWxUFyAACAiV07JPbv318LFy5Ubm6uHnvsMSUkJGj69OnKyMjwXzNx4kTV1tZq7Nixqqqq0mWXXaalS5eqXbt2lsXh8Pl8AfHyqQldrVmbCfycrKjbbXcIQED62P1hsz5/WvzNlj1rwq5XLXtWS6FyAACASbC/W4HkAAAAk4AoqduI1QoAAMCAygEAACZ2rVYIFCQHAACYBPucA9oKAADAgMoBAAAmwT4hkeQAAAATb5CnB7QVAACAAZUDAABMgn1CIskBAAAmwd1UIDkAAOAkwV45YM4BAAAwoHIAAIAJOyQCAAADljICAAA0QOUAAACT4K4bkBwAAHASVisAAAA0QOUAAACTYJ+QSHIAAIBJcKcGtBUAAIAJlQMAAEyCfUIiyQEAACbMOQAAAAbBnRow5wAAAJhQOQAAwIQ5BwAAwMAX5I0F2goAAMCAygEAACa0FQAAgEGwL2WkrQAAAAyoHAAAYBLcdQOSg6CUOn6krho/0jBW/u+9enrofZKk1qFtNPwPN6vvsAFq3baNPi/aoL/lvaSaioN2hAu0mBsz0zQyc4TiusRKkraX7dALz8/Th8s/kiTdcPP1uvqGK9S913+ofYdwDbogVTXVNXaGjGYS7G0FkoMg9WXZbs25+Qn/Z+/RE9Nv0vJu0YVD+mr+3dNV980hpT92m24vyFH+yCl2hAq0mPJ9BzTjyQLt2r5bcjg0bNTVmjb/aY2+4jZtL9uhdmHttGp5iVYtL9E9D99ld7hAsyE5CFLeY8f0zYGTKwHtOoQpadQQvXrvDG0r3iRJev2BAuUWPq9z+p6vnR9va+lQgRZTtOxDw+dZT7+gGzNH6JcX99T2sh1aMPcNSVLigL52hIcWxGoFBKVOXWP0SMlsHfXU64t1W7Vk6uuq2veVzr7oXLVu21plH37qv3b/v/epcs8Bdb34ApIDBI2QkBBdMWyIws5op09KN9odDlpYsG+CZHlysHv3bk2ZMkUvvfSS1Y+GRXau36bX75+j/du/VETnSKXeO1LZbzyiqakPKOKsSB311Kuu+pDhnm8qDqrDWZH2BAy0oPO7n6uX/+dPahvaVodrD+u+2x/S9i1f2B0WWhiVA4tVVlbq5Zdf/t7kwOPxyOPxGMaO+o6ptaOV1eGgEZ+vWO//85ef79LO9ds0+YOZ6nNtsurrjtgXGBAAvvj3Lo0eeqvaR7RXynVD9Fj+H/S7EeNIEBBUmpwcvP322997fvv27T/4DJfLpUcffdQwluTsqeTIi5oaDixQV31IB3Z8qU5do1X2/qdqHdpG7SLOMFQPOnRy6psDVfYFCbSQo/VHtfuLvZKkzZ+UqWef7rrpdzfqyYnP2hwZWhJthSZKS0uTw+GQz/fd/+EcDsf3PiM3N1c5OTmGsT/0GtPUUGCRtmeEquM50ape+L72bNyuo0eO6oIBF+mTpaslSWedG6uos8/SF+u22Bwp0PIcISFqG9rW7jDQwmgrNFFsbKxmz56t4cOHN3p+/fr1SkxM/N5nhIaGKjQ01BgILYUWc/1DN2tTYakq91bI2flMXTVhpHzHvFr39oeq++awSt54T8Mf/q0OHaxR3TeHdcOjt2lH6RYmI+JnL/uhO/Xh8mJ9ubdc4eFn6OobrlS/AX119+jjv8x0PCtKHTt3VHzXsyVJ3Xqcp9qaQ3Lvdau66hs7Qwcs1eTkIDExUaWlpd+ZHPxQVQH2c8ZG6bf52QqP7KCaymptX1um6SPyVFt5/H9uix5/RT6vV7fOyTm+cqHoE/0t70WbowaaX1SnSD0+I0+dOndUzTe12vrZNt09OkclRWskSSMz03Tn/SeqnC+9NVuSNPneJ7X4r/+0JWY0D2+Q/zvm8DXxX/L3339ftbW1uuqqqxo9X1tbq7Vr1+pXv/pVkwKZ0HV0k64HgsGKut12hwAEpI/dH/7wRT/CzefcYNmzXt35D8ue1VKaXDkYNGjQ954PDw9vcmIAAAACB5sgAQBgwrsVAACAQbAvZQyxOwAAABBYqBwAAGDCPgcAAMCAOQcAAMCAOQcAAAANkBwAAGDitfA4XU8//bQcDofGjx/vH6urq1NWVpY6duyo9u3bKz09XeXl5T/iWxpHcgAAgInP57PsOB1r1qzRn/70J/3yl780jE+YMEGLFy/Wm2++qZUrV2rfvn264QbrdnP8FskBAAABpKamRhkZGZo7d67OPPNM//jBgwf14osv6vnnn9evf/1rJSYmat68eVq1apU++ugjS2MgOQAAwMQrn2WHx+NRdXW14fB4PN/53VlZWbr22muVkpJiGC8tLVV9fb1hvHv37oqPj1dxcbGlPz/JAQAAJlbOOXC5XHI6nYbD5XI1+r1/+ctftG7dukbPu91utW3bVpGRkYbx6Ohoud3uH/0zN8RSRgAAmlFubq5ycnIMY6GhoSddt3v3bt17771atmyZ2rVr11LhNYrkAAAAEyv3OQgNDW00GTArLS3V/v37dfHFF/vHjh07pqKiIs2cOVPvvvuujhw5oqqqKkP1oLy8XDExMZbFK5EcAABwEjt2SBw6dKg+/fRTw9htt92m7t27a9KkSerSpYvatGmjwsJCpaenS5LKysq0a9cuJScnWxoLyQEAAAGgQ4cOuuiiiwxj4eHh6tixo398zJgxysnJUVRUlCIiIpSdna3k5GRdeumllsZCcgAAgMnp7k/Q3KZNm6aQkBClp6fL4/EoNTVVs2fPtvx7HL4A+S8woetou0MAAs6Kut12hwAEpI/dHzbr81O7XG3Zs97d/Y5lz2opVA4AADDhxUsAAAANUDkAAMDEjtUKgYTkAAAAkwCZjmcb2goAAMCAygEAACa0FQAAgAGrFQAAABqgcgAAgIk3yCckkhwAAGAS3KkBbQUAAGBC5QAAABNWKwAAAAOSAwAAYMAOiQAAAA1QOQAAwIS2AgAAMGCHRAAAgAaoHAAAYBLsExJJDgAAMAn2OQe0FQAAgAGVAwAATGgrAAAAA9oKAAAADVA5AADAJNj3OSA5AADAxMucAwAA0FCwVw6YcwAAAAyoHAAAYEJbAQAAGNBWAAAAaIDKAQAAJrQVAACAAW0FAACABqgcAABgQlsBAAAY0FYAAABogMoBAAAmPp/X7hBsRXIAAICJN8jbCiQHAACY+IJ8QiJzDgAAgAGVAwAATGgrAAAAA9oKAAAADVA5AADAhB0SAQCAATskAgAANEDlAAAAk2CfkEhyAACASbAvZaStAAAADKgcAABgQlsBAAAYBPtSRtoKAACY+Hw+y46mcLlc6t+/vzp06KDOnTsrLS1NZWVlhmvq6uqUlZWljh07qn379kpPT1d5ebmVPz7JAQAAgWLlypXKysrSRx99pGXLlqm+vl5XXnmlamtr/ddMmDBBixcv1ptvvqmVK1dq3759uuGGGyyNw+ELkMbKhK6j7Q4BCDgr6nbbHQIQkD52f9isz3e2P8+yZx2s+fdp33vgwAF17txZK1eu1OWXX66DBw/qrLPO0oIFCzRy5EhJ0ueff64ePXqouLhYl156qSUxM+cAAAATK39v9ng88ng8hrHQ0FCFhob+4L0HDx6UJEVFRUmSSktLVV9fr5SUFP813bt3V3x8vKXJAW0FAACakcvlktPpNBwul+sH7/N6vRo/frwGDhyoiy66SJLkdrvVtm1bRUZGGq6Njo6W2+22LGYqBwAAmFi5WiE3N1c5OTmGsVOpGmRlZWnjxo364IMPLIvlVJEcAABgYuWLl061hdDQuHHjtGTJEhUVFenss8/2j8fExOjIkSOqqqoyVA/Ky8sVExNjVci0FQAACBQ+n0/jxo3TwoULtXz5ciUkJBjOJyYmqk2bNiosLPSPlZWVadeuXUpOTrYsDioHAACY2LUJUlZWlhYsWKC33npLHTp08M8jcDqdCgsLk9Pp1JgxY5STk6OoqChFREQoOztbycnJlk1GlEgOAAA4iV2r/OfMmSNJGjx4sGF83rx5uvXWWyVJ06ZNU0hIiNLT0+XxeJSamqrZs2dbGgf7HAABjH0OgMY19z4H7drFW/asurpdlj2rpVA5AADAxMoJiT9FJAcAAJgESFHdNiQHAACYBHtywFJGAABgQOUAAACT4K4bBNBqBQQGj8cjl8ul3NzcJu/oBfxc8fcCwYbkAAbV1dVyOp06ePCgIiIi7A4HCAj8vUCwYc4BAAAwIDkAAAAGJAcAAMCA5AAGoaGhmjJlCpOugAb4e4Fgw4REAABgQOUAAAAYkBwAAAADkgMAAGBAcgAAAAxIDuA3a9Ysde3aVe3atVNSUpJWr15td0iArYqKijRs2DDFxcXJ4XBo0aJFdocEtAiSA0iS/vrXvyonJ0dTpkzRunXr1Lt3b6Wmpmr//v12hwbYpra2Vr1799asWbPsDgVoUSxlhCQpKSlJ/fv318yZMyVJXq9XXbp0UXZ2th588EGbowPs53A4tHDhQqWlpdkdCtDsqBxAR44cUWlpqVJSUvxjISEhSklJUXFxsY2RAQDsQHIAVVRU6NixY4qOjjaMR0dHy+122xQVAMAuJAcAAMCA5ADq1KmTWrVqpfLycsN4eXm5YmJibIoKAGAXkgOobdu2SkxMVGFhoX/M6/WqsLBQycnJNkYGALBDa7sDQGDIyclRZmam+vXrp0suuUTTp09XbW2tbrvtNrtDA2xTU1Ojbdu2+T/v2LFD69evV1RUlOLj422MDGheLGWE38yZM/Xss8/K7XarT58+ys/PV1JSkt1hAbZZsWKFhgwZctJ4Zmam5s+f3/IBAS2E5AAAABgw5wAAABiQHAAAAAOSAwAAYEByAAAADEgOAACAAckBAAAwIDkAAAAGJAcAAMCA5AAAABiQHAAAAAOSAwAAYEByAAAADP4PjsLlz4S+JAEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "acc = accuracy_score(y_test, grid_predictions)\r\n",
    "prec = precision_score(y_test, grid_predictions)\r\n",
    "rec = recall_score(y_test, grid_predictions)\r\n",
    "f1 = f1_score(y_test, grid_predictions)\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "roc=roc_auc_score(y_test, grid_predictions)\r\n",
    "model_results = pd.DataFrame([['XGBoost Optimized', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results = results.append(model_results, ignore_index = True)\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.669383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.667778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.599136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gboost</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.637531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN7</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.666914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC Linear</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost Optimized</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.638025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Logistic Regression  0.740260   0.705882  0.444444  0.545455  0.672222\n",
       "1              XGBOOST  0.740260   0.714286  0.432099  0.538462  0.669383\n",
       "2        Random Forest  0.727273   0.673077  0.432099  0.526316  0.659383\n",
       "3                  SGD  0.601732   0.464516  0.888889  0.610169  0.667778\n",
       "4             Adaboost  0.696970   0.666667  0.271605  0.385965  0.599136\n",
       "5               Gboost  0.709957   0.640000  0.395062  0.488550  0.637531\n",
       "6                 KNN7  0.718615   0.625000  0.493827  0.551724  0.666914\n",
       "7           SVC Linear  0.649351   0.000000  0.000000  0.000000  0.500000\n",
       "8   Voting Classifier   0.727273   0.673077  0.432099  0.526316  0.659383\n",
       "9    XGBoost Optimized  0.714286   0.659574  0.382716  0.484375  0.638025"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "import time\r\n",
    "parameters = {\r\n",
    "        'C':[0.1, 1, 10, 100,1000],\r\n",
    "        'gamma':[1, 0.1, 0.01, 0.001,0.0001],\r\n",
    "    'kernel':['rbf','linear']\r\n",
    "        }\r\n",
    "\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "grid_search = GridSearchCV(estimator = svc_model, # Make sure classifier points to the RF model\r\n",
    "                        param_grid = parameters,\r\n",
    "                        scoring = \"accuracy\",\r\n",
    "                        cv = 5,\r\n",
    "                        n_jobs = -1)\r\n",
    "\r\n",
    "t0 = time.time()\r\n",
    "grid_search.fit(X_train_scaled, y_train)\r\n",
    "t1 = time.time()\r\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Took 2.10 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "grid_search.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 1, 'kernel': 'linear'}"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "grid_predictions = grid_search.predict(X_test_scaled)\r\n",
    "acc = accuracy_score(y_test, grid_predictions)\r\n",
    "prec = precision_score(y_test, grid_predictions)\r\n",
    "rec = recall_score(y_test, grid_predictions)\r\n",
    "f1 = f1_score(y_test, grid_predictions)\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "roc=roc_auc_score(y_test, grid_predictions)\r\n",
    "model_results = pd.DataFrame([['SVC Optimized', acc,prec,rec, f1,roc]],\r\n",
    "            columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\r\n",
    "results = results.append(model_results, ignore_index = True)\r\n",
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.669383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.667778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.599136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gboost</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.637531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN7</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.666914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC Linear</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.659383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost Optimized</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.638025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC Optimized</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.540146</td>\n",
       "      <td>0.665062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0   Logistic Regression  0.740260   0.705882  0.444444  0.545455  0.672222\n",
       "1               XGBOOST  0.740260   0.714286  0.432099  0.538462  0.669383\n",
       "2         Random Forest  0.727273   0.673077  0.432099  0.526316  0.659383\n",
       "3                   SGD  0.601732   0.464516  0.888889  0.610169  0.667778\n",
       "4              Adaboost  0.696970   0.666667  0.271605  0.385965  0.599136\n",
       "5                Gboost  0.709957   0.640000  0.395062  0.488550  0.637531\n",
       "6                  KNN7  0.718615   0.625000  0.493827  0.551724  0.666914\n",
       "7            SVC Linear  0.649351   0.000000  0.000000  0.000000  0.500000\n",
       "8    Voting Classifier   0.727273   0.673077  0.432099  0.526316  0.659383\n",
       "9     XGBoost Optimized  0.714286   0.659574  0.382716  0.484375  0.638025\n",
       "10        SVC Optimized  0.727273   0.660714  0.456790  0.540146  0.665062"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "import lightgbm\r\n",
    "train_data = lightgbm.Dataset(X_train_scaled, label=y_train)\r\n",
    "test_data = lightgbm.Dataset(X_test_scaled, label=y_test)\r\n",
    "\r\n",
    "\r\n",
    "#\r\n",
    "# Train the model\r\n",
    "#\r\n",
    "\r\n",
    "parameters = {\r\n",
    "    'application': 'binary',\r\n",
    "    'objective': 'binary',\r\n",
    "    'metric': 'binary_logloss',\r\n",
    "    'max_bin': 200,\r\n",
    "    'boosting': 'gbdt',\r\n",
    "    'num_leaves': 10,\r\n",
    "    'bagging_freq': 20,\r\n",
    "    'learning_rate': 0.003,\r\n",
    "    'verbose': 0\r\n",
    "}\r\n",
    "\r\n",
    "model = lightgbm.train(parameters,\r\n",
    "                    train_data,\r\n",
    "                    valid_sets=test_data,\r\n",
    "                    num_boost_round=5000,\r\n",
    "                    early_stopping_rounds=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[1]\tvalid_0's binary_logloss: 0.64738\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.646905\n",
      "[3]\tvalid_0's binary_logloss: 0.646434\n",
      "[4]\tvalid_0's binary_logloss: 0.646006\n",
      "[5]\tvalid_0's binary_logloss: 0.645583\n",
      "[6]\tvalid_0's binary_logloss: 0.645164\n",
      "[7]\tvalid_0's binary_logloss: 0.64475\n",
      "[8]\tvalid_0's binary_logloss: 0.64434\n",
      "[9]\tvalid_0's binary_logloss: 0.643757\n",
      "[10]\tvalid_0's binary_logloss: 0.64318\n",
      "[11]\tvalid_0's binary_logloss: 0.642608\n",
      "[12]\tvalid_0's binary_logloss: 0.642042\n",
      "[13]\tvalid_0's binary_logloss: 0.641481\n",
      "[14]\tvalid_0's binary_logloss: 0.640926\n",
      "[15]\tvalid_0's binary_logloss: 0.640376\n",
      "[16]\tvalid_0's binary_logloss: 0.639831\n",
      "[17]\tvalid_0's binary_logloss: 0.639291\n",
      "[18]\tvalid_0's binary_logloss: 0.638757\n",
      "[19]\tvalid_0's binary_logloss: 0.638227\n",
      "[20]\tvalid_0's binary_logloss: 0.637703\n",
      "[21]\tvalid_0's binary_logloss: 0.637212\n",
      "[22]\tvalid_0's binary_logloss: 0.636701\n",
      "[23]\tvalid_0's binary_logloss: 0.636191\n",
      "[24]\tvalid_0's binary_logloss: 0.635717\n",
      "[25]\tvalid_0's binary_logloss: 0.635204\n",
      "[26]\tvalid_0's binary_logloss: 0.634709\n",
      "[27]\tvalid_0's binary_logloss: 0.634234\n",
      "[28]\tvalid_0's binary_logloss: 0.633735\n",
      "[29]\tvalid_0's binary_logloss: 0.633256\n",
      "[30]\tvalid_0's binary_logloss: 0.632767\n",
      "[31]\tvalid_0's binary_logloss: 0.632309\n",
      "[32]\tvalid_0's binary_logloss: 0.631829\n",
      "[33]\tvalid_0's binary_logloss: 0.631366\n",
      "[34]\tvalid_0's binary_logloss: 0.630922\n",
      "[35]\tvalid_0's binary_logloss: 0.630455\n",
      "[36]\tvalid_0's binary_logloss: 0.629993\n",
      "[37]\tvalid_0's binary_logloss: 0.629576\n",
      "[38]\tvalid_0's binary_logloss: 0.629123\n",
      "[39]\tvalid_0's binary_logloss: 0.628673\n",
      "[40]\tvalid_0's binary_logloss: 0.628255\n",
      "[41]\tvalid_0's binary_logloss: 0.627826\n",
      "[42]\tvalid_0's binary_logloss: 0.62739\n",
      "[43]\tvalid_0's binary_logloss: 0.626958\n",
      "[44]\tvalid_0's binary_logloss: 0.626556\n",
      "[45]\tvalid_0's binary_logloss: 0.626146\n",
      "[46]\tvalid_0's binary_logloss: 0.625752\n",
      "[47]\tvalid_0's binary_logloss: 0.625362\n",
      "[48]\tvalid_0's binary_logloss: 0.624976\n",
      "[49]\tvalid_0's binary_logloss: 0.624594\n",
      "[50]\tvalid_0's binary_logloss: 0.624217\n",
      "[51]\tvalid_0's binary_logloss: 0.623843\n",
      "[52]\tvalid_0's binary_logloss: 0.623474\n",
      "[53]\tvalid_0's binary_logloss: 0.623109\n",
      "[54]\tvalid_0's binary_logloss: 0.622748\n",
      "[55]\tvalid_0's binary_logloss: 0.62239\n",
      "[56]\tvalid_0's binary_logloss: 0.622037\n",
      "[57]\tvalid_0's binary_logloss: 0.621688\n",
      "[58]\tvalid_0's binary_logloss: 0.621342\n",
      "[59]\tvalid_0's binary_logloss: 0.621\n",
      "[60]\tvalid_0's binary_logloss: 0.620662\n",
      "[61]\tvalid_0's binary_logloss: 0.620328\n",
      "[62]\tvalid_0's binary_logloss: 0.619998\n",
      "[63]\tvalid_0's binary_logloss: 0.619671\n",
      "[64]\tvalid_0's binary_logloss: 0.619348\n",
      "[65]\tvalid_0's binary_logloss: 0.619029\n",
      "[66]\tvalid_0's binary_logloss: 0.618714\n",
      "[67]\tvalid_0's binary_logloss: 0.618402\n",
      "[68]\tvalid_0's binary_logloss: 0.618093\n",
      "[69]\tvalid_0's binary_logloss: 0.617788\n",
      "[70]\tvalid_0's binary_logloss: 0.617487\n",
      "[71]\tvalid_0's binary_logloss: 0.617189\n",
      "[72]\tvalid_0's binary_logloss: 0.616895\n",
      "[73]\tvalid_0's binary_logloss: 0.616604\n",
      "[74]\tvalid_0's binary_logloss: 0.616306\n",
      "[75]\tvalid_0's binary_logloss: 0.616022\n",
      "[76]\tvalid_0's binary_logloss: 0.615741\n",
      "[77]\tvalid_0's binary_logloss: 0.615464\n",
      "[78]\tvalid_0's binary_logloss: 0.61519\n",
      "[79]\tvalid_0's binary_logloss: 0.614857\n",
      "[80]\tvalid_0's binary_logloss: 0.614527\n",
      "[81]\tvalid_0's binary_logloss: 0.614201\n",
      "[82]\tvalid_0's binary_logloss: 0.613878\n",
      "[83]\tvalid_0's binary_logloss: 0.613616\n",
      "[84]\tvalid_0's binary_logloss: 0.6133\n",
      "[85]\tvalid_0's binary_logloss: 0.612988\n",
      "[86]\tvalid_0's binary_logloss: 0.612726\n",
      "[87]\tvalid_0's binary_logloss: 0.612419\n",
      "[88]\tvalid_0's binary_logloss: 0.612116\n",
      "[89]\tvalid_0's binary_logloss: 0.611817\n",
      "[90]\tvalid_0's binary_logloss: 0.611527\n",
      "[91]\tvalid_0's binary_logloss: 0.611241\n",
      "[92]\tvalid_0's binary_logloss: 0.611006\n",
      "[93]\tvalid_0's binary_logloss: 0.61072\n",
      "[94]\tvalid_0's binary_logloss: 0.610436\n",
      "[95]\tvalid_0's binary_logloss: 0.6102\n",
      "[96]\tvalid_0's binary_logloss: 0.609922\n",
      "[97]\tvalid_0's binary_logloss: 0.609643\n",
      "[98]\tvalid_0's binary_logloss: 0.609372\n",
      "[99]\tvalid_0's binary_logloss: 0.609078\n",
      "[100]\tvalid_0's binary_logloss: 0.608812\n",
      "[101]\tvalid_0's binary_logloss: 0.608541\n",
      "[102]\tvalid_0's binary_logloss: 0.608256\n",
      "[103]\tvalid_0's binary_logloss: 0.607979\n",
      "[104]\tvalid_0's binary_logloss: 0.6077\n",
      "[105]\tvalid_0's binary_logloss: 0.607429\n",
      "[106]\tvalid_0's binary_logloss: 0.607179\n",
      "[107]\tvalid_0's binary_logloss: 0.606894\n",
      "[108]\tvalid_0's binary_logloss: 0.60662\n",
      "[109]\tvalid_0's binary_logloss: 0.606345\n",
      "[110]\tvalid_0's binary_logloss: 0.606077\n",
      "[111]\tvalid_0's binary_logloss: 0.605841\n",
      "[112]\tvalid_0's binary_logloss: 0.605579\n",
      "[113]\tvalid_0's binary_logloss: 0.605325\n",
      "[114]\tvalid_0's binary_logloss: 0.605058\n",
      "[115]\tvalid_0's binary_logloss: 0.604804\n",
      "[116]\tvalid_0's binary_logloss: 0.604548\n",
      "[117]\tvalid_0's binary_logloss: 0.604332\n",
      "[118]\tvalid_0's binary_logloss: 0.604086\n",
      "[119]\tvalid_0's binary_logloss: 0.603839\n",
      "[120]\tvalid_0's binary_logloss: 0.603587\n",
      "[121]\tvalid_0's binary_logloss: 0.60335\n",
      "[122]\tvalid_0's binary_logloss: 0.603141\n",
      "[123]\tvalid_0's binary_logloss: 0.602909\n",
      "[124]\tvalid_0's binary_logloss: 0.602675\n",
      "[125]\tvalid_0's binary_logloss: 0.602473\n",
      "[126]\tvalid_0's binary_logloss: 0.602248\n",
      "[127]\tvalid_0's binary_logloss: 0.602052\n",
      "[128]\tvalid_0's binary_logloss: 0.601832\n",
      "[129]\tvalid_0's binary_logloss: 0.601639\n",
      "[130]\tvalid_0's binary_logloss: 0.60142\n",
      "[131]\tvalid_0's binary_logloss: 0.601208\n",
      "[132]\tvalid_0's binary_logloss: 0.601024\n",
      "[133]\tvalid_0's binary_logloss: 0.60084\n",
      "[134]\tvalid_0's binary_logloss: 0.600635\n",
      "[135]\tvalid_0's binary_logloss: 0.600428\n",
      "[136]\tvalid_0's binary_logloss: 0.600228\n",
      "[137]\tvalid_0's binary_logloss: 0.600053\n",
      "[138]\tvalid_0's binary_logloss: 0.599853\n",
      "[139]\tvalid_0's binary_logloss: 0.599689\n",
      "[140]\tvalid_0's binary_logloss: 0.599494\n",
      "[141]\tvalid_0's binary_logloss: 0.599327\n",
      "[142]\tvalid_0's binary_logloss: 0.599152\n",
      "[143]\tvalid_0's binary_logloss: 0.598975\n",
      "[144]\tvalid_0's binary_logloss: 0.598794\n",
      "[145]\tvalid_0's binary_logloss: 0.598635\n",
      "[146]\tvalid_0's binary_logloss: 0.598465\n",
      "[147]\tvalid_0's binary_logloss: 0.598334\n",
      "[148]\tvalid_0's binary_logloss: 0.598169\n",
      "[149]\tvalid_0's binary_logloss: 0.597977\n",
      "[150]\tvalid_0's binary_logloss: 0.597817\n",
      "[151]\tvalid_0's binary_logloss: 0.597658\n",
      "[152]\tvalid_0's binary_logloss: 0.597494\n",
      "[153]\tvalid_0's binary_logloss: 0.597351\n",
      "[154]\tvalid_0's binary_logloss: 0.597198\n",
      "[155]\tvalid_0's binary_logloss: 0.597079\n",
      "[156]\tvalid_0's binary_logloss: 0.59692\n",
      "[157]\tvalid_0's binary_logloss: 0.596784\n",
      "[158]\tvalid_0's binary_logloss: 0.59664\n",
      "[159]\tvalid_0's binary_logloss: 0.596498\n",
      "[160]\tvalid_0's binary_logloss: 0.596328\n",
      "[161]\tvalid_0's binary_logloss: 0.596178\n",
      "[162]\tvalid_0's binary_logloss: 0.596031\n",
      "[163]\tvalid_0's binary_logloss: 0.595914\n",
      "[164]\tvalid_0's binary_logloss: 0.595791\n",
      "[165]\tvalid_0's binary_logloss: 0.595661\n",
      "[166]\tvalid_0's binary_logloss: 0.595522\n",
      "[167]\tvalid_0's binary_logloss: 0.595404\n",
      "[168]\tvalid_0's binary_logloss: 0.59528\n",
      "[169]\tvalid_0's binary_logloss: 0.595126\n",
      "[170]\tvalid_0's binary_logloss: 0.595007\n",
      "[171]\tvalid_0's binary_logloss: 0.594877\n",
      "[172]\tvalid_0's binary_logloss: 0.594754\n",
      "[173]\tvalid_0's binary_logloss: 0.594647\n",
      "[174]\tvalid_0's binary_logloss: 0.5946\n",
      "[175]\tvalid_0's binary_logloss: 0.594556\n",
      "[176]\tvalid_0's binary_logloss: 0.594454\n",
      "[177]\tvalid_0's binary_logloss: 0.594397\n",
      "[178]\tvalid_0's binary_logloss: 0.594357\n",
      "[179]\tvalid_0's binary_logloss: 0.594261\n",
      "[180]\tvalid_0's binary_logloss: 0.594225\n",
      "[181]\tvalid_0's binary_logloss: 0.594126\n",
      "[182]\tvalid_0's binary_logloss: 0.594042\n",
      "[183]\tvalid_0's binary_logloss: 0.593995\n",
      "[184]\tvalid_0's binary_logloss: 0.593965\n",
      "[185]\tvalid_0's binary_logloss: 0.593886\n",
      "[186]\tvalid_0's binary_logloss: 0.593844\n",
      "[187]\tvalid_0's binary_logloss: 0.593767\n",
      "[188]\tvalid_0's binary_logloss: 0.593743\n",
      "[189]\tvalid_0's binary_logloss: 0.593722\n",
      "[190]\tvalid_0's binary_logloss: 0.59365\n",
      "[191]\tvalid_0's binary_logloss: 0.593616\n",
      "[192]\tvalid_0's binary_logloss: 0.593599\n",
      "[193]\tvalid_0's binary_logloss: 0.593531\n",
      "[194]\tvalid_0's binary_logloss: 0.593517\n",
      "[195]\tvalid_0's binary_logloss: 0.593366\n",
      "[196]\tvalid_0's binary_logloss: 0.59322\n",
      "[197]\tvalid_0's binary_logloss: 0.593073\n",
      "[198]\tvalid_0's binary_logloss: 0.592927\n",
      "[199]\tvalid_0's binary_logloss: 0.592842\n",
      "[200]\tvalid_0's binary_logloss: 0.592699\n",
      "[201]\tvalid_0's binary_logloss: 0.592558\n",
      "[202]\tvalid_0's binary_logloss: 0.592477\n",
      "[203]\tvalid_0's binary_logloss: 0.59234\n",
      "[204]\tvalid_0's binary_logloss: 0.592274\n",
      "[205]\tvalid_0's binary_logloss: 0.59214\n",
      "[206]\tvalid_0's binary_logloss: 0.592007\n",
      "[207]\tvalid_0's binary_logloss: 0.591933\n",
      "[208]\tvalid_0's binary_logloss: 0.591804\n",
      "[209]\tvalid_0's binary_logloss: 0.591676\n",
      "[210]\tvalid_0's binary_logloss: 0.591606\n",
      "[211]\tvalid_0's binary_logloss: 0.591481\n",
      "[212]\tvalid_0's binary_logloss: 0.591358\n",
      "[213]\tvalid_0's binary_logloss: 0.591292\n",
      "[214]\tvalid_0's binary_logloss: 0.591172\n",
      "[215]\tvalid_0's binary_logloss: 0.591122\n",
      "[216]\tvalid_0's binary_logloss: 0.591005\n",
      "[217]\tvalid_0's binary_logloss: 0.590889\n",
      "[218]\tvalid_0's binary_logloss: 0.590831\n",
      "[219]\tvalid_0's binary_logloss: 0.590718\n",
      "[220]\tvalid_0's binary_logloss: 0.590606\n",
      "[221]\tvalid_0's binary_logloss: 0.590552\n",
      "[222]\tvalid_0's binary_logloss: 0.590443\n",
      "[223]\tvalid_0's binary_logloss: 0.590337\n",
      "[224]\tvalid_0's binary_logloss: 0.590286\n",
      "[225]\tvalid_0's binary_logloss: 0.590182\n",
      "[226]\tvalid_0's binary_logloss: 0.59008\n",
      "[227]\tvalid_0's binary_logloss: 0.590033\n",
      "[228]\tvalid_0's binary_logloss: 0.589933\n",
      "[229]\tvalid_0's binary_logloss: 0.589835\n",
      "[230]\tvalid_0's binary_logloss: 0.589805\n",
      "[231]\tvalid_0's binary_logloss: 0.589709\n",
      "[232]\tvalid_0's binary_logloss: 0.589615\n",
      "[233]\tvalid_0's binary_logloss: 0.589576\n",
      "[234]\tvalid_0's binary_logloss: 0.589485\n",
      "[235]\tvalid_0's binary_logloss: 0.589448\n",
      "[236]\tvalid_0's binary_logloss: 0.58936\n",
      "[237]\tvalid_0's binary_logloss: 0.589272\n",
      "[238]\tvalid_0's binary_logloss: 0.589264\n",
      "[239]\tvalid_0's binary_logloss: 0.589152\n",
      "[240]\tvalid_0's binary_logloss: 0.589069\n",
      "[241]\tvalid_0's binary_logloss: 0.589072\n",
      "[242]\tvalid_0's binary_logloss: 0.588964\n",
      "[243]\tvalid_0's binary_logloss: 0.588857\n",
      "[244]\tvalid_0's binary_logloss: 0.588864\n",
      "[245]\tvalid_0's binary_logloss: 0.588786\n",
      "[246]\tvalid_0's binary_logloss: 0.588775\n",
      "[247]\tvalid_0's binary_logloss: 0.588673\n",
      "[248]\tvalid_0's binary_logloss: 0.588657\n",
      "[249]\tvalid_0's binary_logloss: 0.588669\n",
      "[250]\tvalid_0's binary_logloss: 0.588571\n",
      "[251]\tvalid_0's binary_logloss: 0.588474\n",
      "[252]\tvalid_0's binary_logloss: 0.58849\n",
      "[253]\tvalid_0's binary_logloss: 0.588469\n",
      "[254]\tvalid_0's binary_logloss: 0.588401\n",
      "[255]\tvalid_0's binary_logloss: 0.588412\n",
      "[256]\tvalid_0's binary_logloss: 0.588385\n",
      "[257]\tvalid_0's binary_logloss: 0.588295\n",
      "[258]\tvalid_0's binary_logloss: 0.588321\n",
      "[259]\tvalid_0's binary_logloss: 0.588234\n",
      "[260]\tvalid_0's binary_logloss: 0.588262\n",
      "[261]\tvalid_0's binary_logloss: 0.588249\n",
      "[262]\tvalid_0's binary_logloss: 0.58819\n",
      "[263]\tvalid_0's binary_logloss: 0.588221\n",
      "[264]\tvalid_0's binary_logloss: 0.588139\n",
      "[265]\tvalid_0's binary_logloss: 0.588129\n",
      "[266]\tvalid_0's binary_logloss: 0.588151\n",
      "[267]\tvalid_0's binary_logloss: 0.588072\n",
      "[268]\tvalid_0's binary_logloss: 0.588058\n",
      "[269]\tvalid_0's binary_logloss: 0.588094\n",
      "[270]\tvalid_0's binary_logloss: 0.588057\n",
      "[271]\tvalid_0's binary_logloss: 0.588096\n",
      "[272]\tvalid_0's binary_logloss: 0.588022\n",
      "[273]\tvalid_0's binary_logloss: 0.587974\n",
      "[274]\tvalid_0's binary_logloss: 0.588016\n",
      "[275]\tvalid_0's binary_logloss: 0.588012\n",
      "[276]\tvalid_0's binary_logloss: 0.587943\n",
      "[277]\tvalid_0's binary_logloss: 0.588004\n",
      "[278]\tvalid_0's binary_logloss: 0.587998\n",
      "[279]\tvalid_0's binary_logloss: 0.588032\n",
      "[280]\tvalid_0's binary_logloss: 0.587967\n",
      "[281]\tvalid_0's binary_logloss: 0.587926\n",
      "[282]\tvalid_0's binary_logloss: 0.587992\n",
      "[283]\tvalid_0's binary_logloss: 0.587974\n",
      "[284]\tvalid_0's binary_logloss: 0.58802\n",
      "[285]\tvalid_0's binary_logloss: 0.58796\n",
      "[286]\tvalid_0's binary_logloss: 0.587957\n",
      "[287]\tvalid_0's binary_logloss: 0.588007\n",
      "[288]\tvalid_0's binary_logloss: 0.588019\n",
      "[289]\tvalid_0's binary_logloss: 0.587962\n",
      "[290]\tvalid_0's binary_logloss: 0.588015\n",
      "[291]\tvalid_0's binary_logloss: 0.588007\n",
      "[292]\tvalid_0's binary_logloss: 0.588022\n",
      "[293]\tvalid_0's binary_logloss: 0.588077\n",
      "[294]\tvalid_0's binary_logloss: 0.588081\n",
      "[295]\tvalid_0's binary_logloss: 0.588089\n",
      "[296]\tvalid_0's binary_logloss: 0.588147\n",
      "[297]\tvalid_0's binary_logloss: 0.588108\n",
      "[298]\tvalid_0's binary_logloss: 0.588119\n",
      "[299]\tvalid_0's binary_logloss: 0.588158\n",
      "[300]\tvalid_0's binary_logloss: 0.588154\n",
      "[301]\tvalid_0's binary_logloss: 0.588217\n",
      "[302]\tvalid_0's binary_logloss: 0.58816\n",
      "[303]\tvalid_0's binary_logloss: 0.58814\n",
      "[304]\tvalid_0's binary_logloss: 0.588107\n",
      "[305]\tvalid_0's binary_logloss: 0.587985\n",
      "[306]\tvalid_0's binary_logloss: 0.587864\n",
      "[307]\tvalid_0's binary_logloss: 0.587745\n",
      "[308]\tvalid_0's binary_logloss: 0.587624\n",
      "[309]\tvalid_0's binary_logloss: 0.587506\n",
      "[310]\tvalid_0's binary_logloss: 0.587387\n",
      "[311]\tvalid_0's binary_logloss: 0.587272\n",
      "[312]\tvalid_0's binary_logloss: 0.587158\n",
      "[313]\tvalid_0's binary_logloss: 0.587042\n",
      "[314]\tvalid_0's binary_logloss: 0.58693\n",
      "[315]\tvalid_0's binary_logloss: 0.586817\n",
      "[316]\tvalid_0's binary_logloss: 0.586707\n",
      "[317]\tvalid_0's binary_logloss: 0.586604\n",
      "[318]\tvalid_0's binary_logloss: 0.586499\n",
      "[319]\tvalid_0's binary_logloss: 0.586398\n",
      "[320]\tvalid_0's binary_logloss: 0.586296\n",
      "[321]\tvalid_0's binary_logloss: 0.586197\n",
      "[322]\tvalid_0's binary_logloss: 0.586095\n",
      "[323]\tvalid_0's binary_logloss: 0.585996\n",
      "[324]\tvalid_0's binary_logloss: 0.585901\n",
      "[325]\tvalid_0's binary_logloss: 0.585804\n",
      "[326]\tvalid_0's binary_logloss: 0.585712\n",
      "[327]\tvalid_0's binary_logloss: 0.585614\n",
      "[328]\tvalid_0's binary_logloss: 0.585518\n",
      "[329]\tvalid_0's binary_logloss: 0.585428\n",
      "[330]\tvalid_0's binary_logloss: 0.58534\n",
      "[331]\tvalid_0's binary_logloss: 0.585221\n",
      "[332]\tvalid_0's binary_logloss: 0.585135\n",
      "[333]\tvalid_0's binary_logloss: 0.585012\n",
      "[334]\tvalid_0's binary_logloss: 0.58491\n",
      "[335]\tvalid_0's binary_logloss: 0.58481\n",
      "[336]\tvalid_0's binary_logloss: 0.584682\n",
      "[337]\tvalid_0's binary_logloss: 0.584584\n",
      "[338]\tvalid_0's binary_logloss: 0.584459\n",
      "[339]\tvalid_0's binary_logloss: 0.584363\n",
      "[340]\tvalid_0's binary_logloss: 0.584239\n",
      "[341]\tvalid_0's binary_logloss: 0.584146\n",
      "[342]\tvalid_0's binary_logloss: 0.584053\n",
      "[343]\tvalid_0's binary_logloss: 0.583933\n",
      "[344]\tvalid_0's binary_logloss: 0.583843\n",
      "[345]\tvalid_0's binary_logloss: 0.583725\n",
      "[346]\tvalid_0's binary_logloss: 0.583637\n",
      "[347]\tvalid_0's binary_logloss: 0.583521\n",
      "[348]\tvalid_0's binary_logloss: 0.583435\n",
      "[349]\tvalid_0's binary_logloss: 0.583321\n",
      "[350]\tvalid_0's binary_logloss: 0.583237\n",
      "[351]\tvalid_0's binary_logloss: 0.583154\n",
      "[352]\tvalid_0's binary_logloss: 0.583038\n",
      "[353]\tvalid_0's binary_logloss: 0.582957\n",
      "[354]\tvalid_0's binary_logloss: 0.582849\n",
      "[355]\tvalid_0's binary_logloss: 0.58277\n",
      "[356]\tvalid_0's binary_logloss: 0.582663\n",
      "[357]\tvalid_0's binary_logloss: 0.582586\n",
      "[358]\tvalid_0's binary_logloss: 0.58251\n",
      "[359]\tvalid_0's binary_logloss: 0.582407\n",
      "[360]\tvalid_0's binary_logloss: 0.582332\n",
      "[361]\tvalid_0's binary_logloss: 0.582231\n",
      "[362]\tvalid_0's binary_logloss: 0.582191\n",
      "[363]\tvalid_0's binary_logloss: 0.582119\n",
      "[364]\tvalid_0's binary_logloss: 0.582081\n",
      "[365]\tvalid_0's binary_logloss: 0.581983\n",
      "[366]\tvalid_0's binary_logloss: 0.581946\n",
      "[367]\tvalid_0's binary_logloss: 0.581888\n",
      "[368]\tvalid_0's binary_logloss: 0.581871\n",
      "[369]\tvalid_0's binary_logloss: 0.581786\n",
      "[370]\tvalid_0's binary_logloss: 0.581834\n",
      "[371]\tvalid_0's binary_logloss: 0.581907\n",
      "[372]\tvalid_0's binary_logloss: 0.581875\n",
      "[373]\tvalid_0's binary_logloss: 0.581821\n",
      "[374]\tvalid_0's binary_logloss: 0.581741\n",
      "[375]\tvalid_0's binary_logloss: 0.581792\n",
      "[376]\tvalid_0's binary_logloss: 0.581869\n",
      "[377]\tvalid_0's binary_logloss: 0.581846\n",
      "[378]\tvalid_0's binary_logloss: 0.581796\n",
      "[379]\tvalid_0's binary_logloss: 0.58185\n",
      "[380]\tvalid_0's binary_logloss: 0.58183\n",
      "[381]\tvalid_0's binary_logloss: 0.581886\n",
      "[382]\tvalid_0's binary_logloss: 0.581866\n",
      "[383]\tvalid_0's binary_logloss: 0.581792\n",
      "[384]\tvalid_0's binary_logloss: 0.581874\n",
      "[385]\tvalid_0's binary_logloss: 0.581857\n",
      "[386]\tvalid_0's binary_logloss: 0.581917\n",
      "[387]\tvalid_0's binary_logloss: 0.581901\n",
      "[388]\tvalid_0's binary_logloss: 0.581986\n",
      "[389]\tvalid_0's binary_logloss: 0.581972\n",
      "[390]\tvalid_0's binary_logloss: 0.581984\n",
      "[391]\tvalid_0's binary_logloss: 0.581996\n",
      "[392]\tvalid_0's binary_logloss: 0.582083\n",
      "[393]\tvalid_0's binary_logloss: 0.582096\n",
      "[394]\tvalid_0's binary_logloss: 0.582027\n",
      "[395]\tvalid_0's binary_logloss: 0.582064\n",
      "[396]\tvalid_0's binary_logloss: 0.582153\n",
      "[397]\tvalid_0's binary_logloss: 0.582191\n",
      "[398]\tvalid_0's binary_logloss: 0.582282\n",
      "[399]\tvalid_0's binary_logloss: 0.582375\n",
      "[400]\tvalid_0's binary_logloss: 0.582414\n",
      "[401]\tvalid_0's binary_logloss: 0.582483\n",
      "[402]\tvalid_0's binary_logloss: 0.582578\n",
      "[403]\tvalid_0's binary_logloss: 0.582619\n",
      "[404]\tvalid_0's binary_logloss: 0.582714\n",
      "[405]\tvalid_0's binary_logloss: 0.582786\n",
      "[406]\tvalid_0's binary_logloss: 0.582884\n",
      "[407]\tvalid_0's binary_logloss: 0.582927\n",
      "[408]\tvalid_0's binary_logloss: 0.58303\n",
      "[409]\tvalid_0's binary_logloss: 0.583074\n",
      "[410]\tvalid_0's binary_logloss: 0.583118\n",
      "[411]\tvalid_0's binary_logloss: 0.583169\n",
      "[412]\tvalid_0's binary_logloss: 0.583215\n",
      "[413]\tvalid_0's binary_logloss: 0.583267\n",
      "[414]\tvalid_0's binary_logloss: 0.583313\n",
      "[415]\tvalid_0's binary_logloss: 0.58336\n",
      "[416]\tvalid_0's binary_logloss: 0.583404\n",
      "[417]\tvalid_0's binary_logloss: 0.583452\n",
      "[418]\tvalid_0's binary_logloss: 0.583497\n",
      "[419]\tvalid_0's binary_logloss: 0.583535\n",
      "[420]\tvalid_0's binary_logloss: 0.583573\n",
      "[421]\tvalid_0's binary_logloss: 0.583613\n",
      "[422]\tvalid_0's binary_logloss: 0.583653\n",
      "[423]\tvalid_0's binary_logloss: 0.583656\n",
      "[424]\tvalid_0's binary_logloss: 0.583706\n",
      "[425]\tvalid_0's binary_logloss: 0.583792\n",
      "[426]\tvalid_0's binary_logloss: 0.583777\n",
      "[427]\tvalid_0's binary_logloss: 0.583815\n",
      "[428]\tvalid_0's binary_logloss: 0.583865\n",
      "[429]\tvalid_0's binary_logloss: 0.58388\n",
      "[430]\tvalid_0's binary_logloss: 0.583868\n",
      "[431]\tvalid_0's binary_logloss: 0.583907\n",
      "[432]\tvalid_0's binary_logloss: 0.583895\n",
      "[433]\tvalid_0's binary_logloss: 0.583913\n",
      "[434]\tvalid_0's binary_logloss: 0.583903\n",
      "[435]\tvalid_0's binary_logloss: 0.583943\n",
      "[436]\tvalid_0's binary_logloss: 0.584036\n",
      "[437]\tvalid_0's binary_logloss: 0.584\n",
      "[438]\tvalid_0's binary_logloss: 0.584094\n",
      "[439]\tvalid_0's binary_logloss: 0.584072\n",
      "[440]\tvalid_0's binary_logloss: 0.584128\n",
      "[441]\tvalid_0's binary_logloss: 0.584094\n",
      "[442]\tvalid_0's binary_logloss: 0.584087\n",
      "[443]\tvalid_0's binary_logloss: 0.58408\n",
      "[444]\tvalid_0's binary_logloss: 0.584048\n",
      "[445]\tvalid_0's binary_logloss: 0.584043\n",
      "[446]\tvalid_0's binary_logloss: 0.584038\n",
      "[447]\tvalid_0's binary_logloss: 0.584161\n",
      "[448]\tvalid_0's binary_logloss: 0.584131\n",
      "[449]\tvalid_0's binary_logloss: 0.584102\n",
      "[450]\tvalid_0's binary_logloss: 0.584227\n",
      "[451]\tvalid_0's binary_logloss: 0.58426\n",
      "[452]\tvalid_0's binary_logloss: 0.584232\n",
      "[453]\tvalid_0's binary_logloss: 0.584359\n",
      "[454]\tvalid_0's binary_logloss: 0.584349\n",
      "[455]\tvalid_0's binary_logloss: 0.584476\n",
      "[456]\tvalid_0's binary_logloss: 0.584479\n",
      "[457]\tvalid_0's binary_logloss: 0.584581\n",
      "[458]\tvalid_0's binary_logloss: 0.584573\n",
      "[459]\tvalid_0's binary_logloss: 0.584632\n",
      "[460]\tvalid_0's binary_logloss: 0.584656\n",
      "[461]\tvalid_0's binary_logloss: 0.584676\n",
      "[462]\tvalid_0's binary_logloss: 0.58469\n",
      "[463]\tvalid_0's binary_logloss: 0.584705\n",
      "[464]\tvalid_0's binary_logloss: 0.584624\n",
      "[465]\tvalid_0's binary_logloss: 0.584545\n",
      "[466]\tvalid_0's binary_logloss: 0.584561\n",
      "[467]\tvalid_0's binary_logloss: 0.584483\n",
      "[468]\tvalid_0's binary_logloss: 0.584533\n",
      "[469]\tvalid_0's binary_logloss: 0.584666\n",
      "[470]\tvalid_0's binary_logloss: 0.584799\n",
      "[471]\tvalid_0's binary_logloss: 0.584817\n",
      "[472]\tvalid_0's binary_logloss: 0.584837\n",
      "[473]\tvalid_0's binary_logloss: 0.584761\n",
      "[474]\tvalid_0's binary_logloss: 0.584896\n",
      "Early stopping, best iteration is:\n",
      "[374]\tvalid_0's binary_logloss: 0.581741\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}